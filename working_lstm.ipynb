{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stockstats import StockDataFrame as sdf\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import alpaca_trade_api as tradeapi\n",
    "from pathlib import Path\n",
    "import lib_copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Python-dotenv could not parse statement starting at line 7\nPython-dotenv could not parse statement starting at line 8\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = lib_copy.fetch_ohlcv(\"JPM\", \"2017-01-01\", \"2019-01-01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_boll_kelt_ewma_dataframe(dataframe):\n",
    "    lib_copy.bollinger_band_generator(dataframe)\n",
    "    lib_copy.keltner_channel(dataframe)\n",
    "    lib_copy.ewma(dataframe)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = adding_boll_kelt_ewma_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "61"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# Looking for missing values\n",
    "everything.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                            open    high     low  close  volume  \\\n2017-01-04 12:15:00-05:00  86.74  86.820  86.730  86.80   18457   \n2017-01-04 12:30:00-05:00  86.81  86.875  86.780  86.81   24608   \n2017-01-04 12:45:00-05:00  86.81  86.860  86.770  86.86   14159   \n2017-01-04 13:00:00-05:00  86.86  86.880  86.830  86.88   12004   \n2017-01-04 13:15:00-05:00  86.89  86.890  86.811  86.87   13286   \n...                          ...     ...     ...    ...     ...   \n2018-12-31 14:45:00-05:00  97.02  97.300  97.020  97.02   14407   \n2018-12-31 15:00:00-05:00  97.04  97.290  97.000  97.12   17428   \n2018-12-31 15:15:00-05:00  97.10  97.260  96.950  97.20   20678   \n2018-12-31 15:30:00-05:00  97.21  97.560  97.200  97.53   28610   \n2018-12-31 15:45:00-05:00  97.62  97.730  96.850  97.73   91056   \n\n                           bollinger_band_middle  bollinger_band_std  \\\n2017-01-04 12:15:00-05:00               86.66975            0.215116   \n2017-01-04 12:30:00-05:00               86.68575            0.212932   \n2017-01-04 12:45:00-05:00               86.70950            0.203921   \n2017-01-04 13:00:00-05:00               86.73300            0.194452   \n2017-01-04 13:15:00-05:00               86.74500            0.195165   \n...                                          ...                 ...   \n2018-12-31 14:45:00-05:00               97.24175            0.200862   \n2018-12-31 15:00:00-05:00               97.22325            0.193705   \n2018-12-31 15:15:00-05:00               97.22025            0.193571   \n2018-12-31 15:30:00-05:00               97.22175            0.195954   \n2018-12-31 15:45:00-05:00               97.23225            0.217246   \n\n                           bollinger_band_upper  bollinger_band_lower  \\\n2017-01-04 12:15:00-05:00             87.099982             86.239518   \n2017-01-04 12:30:00-05:00             87.111615             86.259885   \n2017-01-04 12:45:00-05:00             87.117343             86.301657   \n2017-01-04 13:00:00-05:00             87.121904             86.344096   \n2017-01-04 13:15:00-05:00             87.135330             86.354670   \n...                                         ...                   ...   \n2018-12-31 14:45:00-05:00             97.643474             96.840026   \n2018-12-31 15:00:00-05:00             97.610661             96.835839   \n2018-12-31 15:15:00-05:00             97.607392             96.833108   \n2018-12-31 15:30:00-05:00             97.613659             96.829841   \n2018-12-31 15:45:00-05:00             97.666743             96.797757   \n\n                           close_-1_s     tr  tr_14_smma       atr     kcmid  \\\n2017-01-04 12:15:00-05:00       86.75  0.090    0.203311  0.203311  86.66975   \n2017-01-04 12:30:00-05:00       86.80  0.095    0.193300  0.193300  86.68575   \n2017-01-04 12:45:00-05:00       86.81  0.090    0.183949  0.183949  86.70950   \n2017-01-04 13:00:00-05:00       86.86  0.050    0.172051  0.172051  86.73300   \n2017-01-04 13:15:00-05:00       86.88  0.079    0.163927  0.163927  86.74500   \n...                               ...    ...         ...       ...       ...   \n2018-12-31 14:45:00-05:00       96.95  0.350    0.369462  0.369462  97.24175   \n2018-12-31 15:00:00-05:00       97.02  0.290    0.363786  0.363786  97.22325   \n2018-12-31 15:15:00-05:00       97.12  0.310    0.359944  0.359944  97.22025   \n2018-12-31 15:30:00-05:00       97.20  0.360    0.359948  0.359948  97.22175   \n2018-12-31 15:45:00-05:00       97.53  0.880    0.397095  0.397095  97.23225   \n\n                                kcup       kclo       EMA9      EMA21  \n2017-01-04 12:15:00-05:00  86.873061  86.466439  86.713479  86.661031  \n2017-01-04 12:30:00-05:00  86.879050  86.492450  86.732783  86.674573  \n2017-01-04 12:45:00-05:00  86.893449  86.525551  86.758226  86.691430  \n2017-01-04 13:00:00-05:00  86.905051  86.560949  86.782581  86.708573  \n2017-01-04 13:15:00-05:00  86.908927  86.581073  86.800065  86.723248  \n...                              ...        ...        ...        ...  \n2018-12-31 14:45:00-05:00  97.611212  96.872288  97.111437  97.189987  \n2018-12-31 15:00:00-05:00  97.587036  96.859464  97.113150  97.183624  \n2018-12-31 15:15:00-05:00  97.580194  96.860306  97.130520  97.185113  \n2018-12-31 15:30:00-05:00  97.581698  96.861802  97.210416  97.216466  \n2018-12-31 15:45:00-05:00  97.629345  96.835155  97.314333  97.263151  \n\n[12909 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>bollinger_band_middle</th>\n      <th>bollinger_band_std</th>\n      <th>bollinger_band_upper</th>\n      <th>bollinger_band_lower</th>\n      <th>close_-1_s</th>\n      <th>tr</th>\n      <th>tr_14_smma</th>\n      <th>atr</th>\n      <th>kcmid</th>\n      <th>kcup</th>\n      <th>kclo</th>\n      <th>EMA9</th>\n      <th>EMA21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-04 12:15:00-05:00</th>\n      <td>86.74</td>\n      <td>86.820</td>\n      <td>86.730</td>\n      <td>86.80</td>\n      <td>18457</td>\n      <td>86.66975</td>\n      <td>0.215116</td>\n      <td>87.099982</td>\n      <td>86.239518</td>\n      <td>86.75</td>\n      <td>0.090</td>\n      <td>0.203311</td>\n      <td>0.203311</td>\n      <td>86.66975</td>\n      <td>86.873061</td>\n      <td>86.466439</td>\n      <td>86.713479</td>\n      <td>86.661031</td>\n    </tr>\n    <tr>\n      <th>2017-01-04 12:30:00-05:00</th>\n      <td>86.81</td>\n      <td>86.875</td>\n      <td>86.780</td>\n      <td>86.81</td>\n      <td>24608</td>\n      <td>86.68575</td>\n      <td>0.212932</td>\n      <td>87.111615</td>\n      <td>86.259885</td>\n      <td>86.80</td>\n      <td>0.095</td>\n      <td>0.193300</td>\n      <td>0.193300</td>\n      <td>86.68575</td>\n      <td>86.879050</td>\n      <td>86.492450</td>\n      <td>86.732783</td>\n      <td>86.674573</td>\n    </tr>\n    <tr>\n      <th>2017-01-04 12:45:00-05:00</th>\n      <td>86.81</td>\n      <td>86.860</td>\n      <td>86.770</td>\n      <td>86.86</td>\n      <td>14159</td>\n      <td>86.70950</td>\n      <td>0.203921</td>\n      <td>87.117343</td>\n      <td>86.301657</td>\n      <td>86.81</td>\n      <td>0.090</td>\n      <td>0.183949</td>\n      <td>0.183949</td>\n      <td>86.70950</td>\n      <td>86.893449</td>\n      <td>86.525551</td>\n      <td>86.758226</td>\n      <td>86.691430</td>\n    </tr>\n    <tr>\n      <th>2017-01-04 13:00:00-05:00</th>\n      <td>86.86</td>\n      <td>86.880</td>\n      <td>86.830</td>\n      <td>86.88</td>\n      <td>12004</td>\n      <td>86.73300</td>\n      <td>0.194452</td>\n      <td>87.121904</td>\n      <td>86.344096</td>\n      <td>86.86</td>\n      <td>0.050</td>\n      <td>0.172051</td>\n      <td>0.172051</td>\n      <td>86.73300</td>\n      <td>86.905051</td>\n      <td>86.560949</td>\n      <td>86.782581</td>\n      <td>86.708573</td>\n    </tr>\n    <tr>\n      <th>2017-01-04 13:15:00-05:00</th>\n      <td>86.89</td>\n      <td>86.890</td>\n      <td>86.811</td>\n      <td>86.87</td>\n      <td>13286</td>\n      <td>86.74500</td>\n      <td>0.195165</td>\n      <td>87.135330</td>\n      <td>86.354670</td>\n      <td>86.88</td>\n      <td>0.079</td>\n      <td>0.163927</td>\n      <td>0.163927</td>\n      <td>86.74500</td>\n      <td>86.908927</td>\n      <td>86.581073</td>\n      <td>86.800065</td>\n      <td>86.723248</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-12-31 14:45:00-05:00</th>\n      <td>97.02</td>\n      <td>97.300</td>\n      <td>97.020</td>\n      <td>97.02</td>\n      <td>14407</td>\n      <td>97.24175</td>\n      <td>0.200862</td>\n      <td>97.643474</td>\n      <td>96.840026</td>\n      <td>96.95</td>\n      <td>0.350</td>\n      <td>0.369462</td>\n      <td>0.369462</td>\n      <td>97.24175</td>\n      <td>97.611212</td>\n      <td>96.872288</td>\n      <td>97.111437</td>\n      <td>97.189987</td>\n    </tr>\n    <tr>\n      <th>2018-12-31 15:00:00-05:00</th>\n      <td>97.04</td>\n      <td>97.290</td>\n      <td>97.000</td>\n      <td>97.12</td>\n      <td>17428</td>\n      <td>97.22325</td>\n      <td>0.193705</td>\n      <td>97.610661</td>\n      <td>96.835839</td>\n      <td>97.02</td>\n      <td>0.290</td>\n      <td>0.363786</td>\n      <td>0.363786</td>\n      <td>97.22325</td>\n      <td>97.587036</td>\n      <td>96.859464</td>\n      <td>97.113150</td>\n      <td>97.183624</td>\n    </tr>\n    <tr>\n      <th>2018-12-31 15:15:00-05:00</th>\n      <td>97.10</td>\n      <td>97.260</td>\n      <td>96.950</td>\n      <td>97.20</td>\n      <td>20678</td>\n      <td>97.22025</td>\n      <td>0.193571</td>\n      <td>97.607392</td>\n      <td>96.833108</td>\n      <td>97.12</td>\n      <td>0.310</td>\n      <td>0.359944</td>\n      <td>0.359944</td>\n      <td>97.22025</td>\n      <td>97.580194</td>\n      <td>96.860306</td>\n      <td>97.130520</td>\n      <td>97.185113</td>\n    </tr>\n    <tr>\n      <th>2018-12-31 15:30:00-05:00</th>\n      <td>97.21</td>\n      <td>97.560</td>\n      <td>97.200</td>\n      <td>97.53</td>\n      <td>28610</td>\n      <td>97.22175</td>\n      <td>0.195954</td>\n      <td>97.613659</td>\n      <td>96.829841</td>\n      <td>97.20</td>\n      <td>0.360</td>\n      <td>0.359948</td>\n      <td>0.359948</td>\n      <td>97.22175</td>\n      <td>97.581698</td>\n      <td>96.861802</td>\n      <td>97.210416</td>\n      <td>97.216466</td>\n    </tr>\n    <tr>\n      <th>2018-12-31 15:45:00-05:00</th>\n      <td>97.62</td>\n      <td>97.730</td>\n      <td>96.850</td>\n      <td>97.73</td>\n      <td>91056</td>\n      <td>97.23225</td>\n      <td>0.217246</td>\n      <td>97.666743</td>\n      <td>96.797757</td>\n      <td>97.53</td>\n      <td>0.880</td>\n      <td>0.397095</td>\n      <td>0.397095</td>\n      <td>97.23225</td>\n      <td>97.629345</td>\n      <td>96.835155</td>\n      <td>97.314333</td>\n      <td>97.263151</td>\n    </tr>\n  </tbody>\n</table>\n<p>12909 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Filling missing values with the previous ones\n",
    "everything = df.dropna()\n",
    "everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "             open    high     low  close  volume  bollinger_band_middle  \\\n2017-01-04  86.74  86.820  86.730  86.80   18457               86.66975   \n2017-01-04  86.81  86.875  86.780  86.81   24608               86.68575   \n2017-01-04  86.81  86.860  86.770  86.86   14159               86.70950   \n2017-01-04  86.86  86.880  86.830  86.88   12004               86.73300   \n2017-01-04  86.89  86.890  86.811  86.87   13286               86.74500   \n...           ...     ...     ...    ...     ...                    ...   \n2018-12-31  97.02  97.300  97.020  97.02   14407               97.24175   \n2018-12-31  97.04  97.290  97.000  97.12   17428               97.22325   \n2018-12-31  97.10  97.260  96.950  97.20   20678               97.22025   \n2018-12-31  97.21  97.560  97.200  97.53   28610               97.22175   \n2018-12-31  97.62  97.730  96.850  97.73   91056               97.23225   \n\n            bollinger_band_std  bollinger_band_upper  bollinger_band_lower  \\\n2017-01-04            0.215116             87.099982             86.239518   \n2017-01-04            0.212932             87.111615             86.259885   \n2017-01-04            0.203921             87.117343             86.301657   \n2017-01-04            0.194452             87.121904             86.344096   \n2017-01-04            0.195165             87.135330             86.354670   \n...                        ...                   ...                   ...   \n2018-12-31            0.200862             97.643474             96.840026   \n2018-12-31            0.193705             97.610661             96.835839   \n2018-12-31            0.193571             97.607392             96.833108   \n2018-12-31            0.195954             97.613659             96.829841   \n2018-12-31            0.217246             97.666743             96.797757   \n\n            close_-1_s  ...     kcmid       kcup       kclo       EMA9  \\\n2017-01-04       86.75  ...  86.66975  86.873061  86.466439  86.713479   \n2017-01-04       86.80  ...  86.68575  86.879050  86.492450  86.732783   \n2017-01-04       86.81  ...  86.70950  86.893449  86.525551  86.758226   \n2017-01-04       86.86  ...  86.73300  86.905051  86.560949  86.782581   \n2017-01-04       86.88  ...  86.74500  86.908927  86.581073  86.800065   \n...                ...  ...       ...        ...        ...        ...   \n2018-12-31       96.95  ...  97.24175  97.611212  96.872288  97.111437   \n2018-12-31       97.02  ...  97.22325  97.587036  96.859464  97.113150   \n2018-12-31       97.12  ...  97.22025  97.580194  96.860306  97.130520   \n2018-12-31       97.20  ...  97.22175  97.581698  96.861802  97.210416   \n2018-12-31       97.53  ...  97.23225  97.629345  96.835155  97.314333   \n\n                EMA21  squeeze  crossup  crossdown  target  io_target  \n2017-01-04  86.661031      0.0      0.0        0.0     0.0        0.0  \n2017-01-04  86.674573      0.0      0.0        0.0     0.0        0.0  \n2017-01-04  86.691430      0.0      0.0        0.0     0.0        0.0  \n2017-01-04  86.708573      0.0      0.0        0.0     0.0        0.0  \n2017-01-04  86.723248      0.0      0.0        0.0     0.0        0.0  \n...               ...      ...      ...        ...     ...        ...  \n2018-12-31  97.189987      0.0      0.0        0.0     0.0        0.0  \n2018-12-31  97.183624      0.0      0.0        0.0     0.0        0.0  \n2018-12-31  97.185113      0.0      0.0        0.0     0.0        0.0  \n2018-12-31  97.216466      0.0      0.0        0.0     0.0        0.0  \n2018-12-31  97.263151      0.0      1.0        0.0     0.0        1.0  \n\n[12909 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>bollinger_band_middle</th>\n      <th>bollinger_band_std</th>\n      <th>bollinger_band_upper</th>\n      <th>bollinger_band_lower</th>\n      <th>close_-1_s</th>\n      <th>...</th>\n      <th>kcmid</th>\n      <th>kcup</th>\n      <th>kclo</th>\n      <th>EMA9</th>\n      <th>EMA21</th>\n      <th>squeeze</th>\n      <th>crossup</th>\n      <th>crossdown</th>\n      <th>target</th>\n      <th>io_target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-04</th>\n      <td>86.74</td>\n      <td>86.820</td>\n      <td>86.730</td>\n      <td>86.80</td>\n      <td>18457</td>\n      <td>86.66975</td>\n      <td>0.215116</td>\n      <td>87.099982</td>\n      <td>86.239518</td>\n      <td>86.75</td>\n      <td>...</td>\n      <td>86.66975</td>\n      <td>86.873061</td>\n      <td>86.466439</td>\n      <td>86.713479</td>\n      <td>86.661031</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-04</th>\n      <td>86.81</td>\n      <td>86.875</td>\n      <td>86.780</td>\n      <td>86.81</td>\n      <td>24608</td>\n      <td>86.68575</td>\n      <td>0.212932</td>\n      <td>87.111615</td>\n      <td>86.259885</td>\n      <td>86.80</td>\n      <td>...</td>\n      <td>86.68575</td>\n      <td>86.879050</td>\n      <td>86.492450</td>\n      <td>86.732783</td>\n      <td>86.674573</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-04</th>\n      <td>86.81</td>\n      <td>86.860</td>\n      <td>86.770</td>\n      <td>86.86</td>\n      <td>14159</td>\n      <td>86.70950</td>\n      <td>0.203921</td>\n      <td>87.117343</td>\n      <td>86.301657</td>\n      <td>86.81</td>\n      <td>...</td>\n      <td>86.70950</td>\n      <td>86.893449</td>\n      <td>86.525551</td>\n      <td>86.758226</td>\n      <td>86.691430</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-04</th>\n      <td>86.86</td>\n      <td>86.880</td>\n      <td>86.830</td>\n      <td>86.88</td>\n      <td>12004</td>\n      <td>86.73300</td>\n      <td>0.194452</td>\n      <td>87.121904</td>\n      <td>86.344096</td>\n      <td>86.86</td>\n      <td>...</td>\n      <td>86.73300</td>\n      <td>86.905051</td>\n      <td>86.560949</td>\n      <td>86.782581</td>\n      <td>86.708573</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2017-01-04</th>\n      <td>86.89</td>\n      <td>86.890</td>\n      <td>86.811</td>\n      <td>86.87</td>\n      <td>13286</td>\n      <td>86.74500</td>\n      <td>0.195165</td>\n      <td>87.135330</td>\n      <td>86.354670</td>\n      <td>86.88</td>\n      <td>...</td>\n      <td>86.74500</td>\n      <td>86.908927</td>\n      <td>86.581073</td>\n      <td>86.800065</td>\n      <td>86.723248</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>97.02</td>\n      <td>97.300</td>\n      <td>97.020</td>\n      <td>97.02</td>\n      <td>14407</td>\n      <td>97.24175</td>\n      <td>0.200862</td>\n      <td>97.643474</td>\n      <td>96.840026</td>\n      <td>96.95</td>\n      <td>...</td>\n      <td>97.24175</td>\n      <td>97.611212</td>\n      <td>96.872288</td>\n      <td>97.111437</td>\n      <td>97.189987</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>97.04</td>\n      <td>97.290</td>\n      <td>97.000</td>\n      <td>97.12</td>\n      <td>17428</td>\n      <td>97.22325</td>\n      <td>0.193705</td>\n      <td>97.610661</td>\n      <td>96.835839</td>\n      <td>97.02</td>\n      <td>...</td>\n      <td>97.22325</td>\n      <td>97.587036</td>\n      <td>96.859464</td>\n      <td>97.113150</td>\n      <td>97.183624</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>97.10</td>\n      <td>97.260</td>\n      <td>96.950</td>\n      <td>97.20</td>\n      <td>20678</td>\n      <td>97.22025</td>\n      <td>0.193571</td>\n      <td>97.607392</td>\n      <td>96.833108</td>\n      <td>97.12</td>\n      <td>...</td>\n      <td>97.22025</td>\n      <td>97.580194</td>\n      <td>96.860306</td>\n      <td>97.130520</td>\n      <td>97.185113</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>97.21</td>\n      <td>97.560</td>\n      <td>97.200</td>\n      <td>97.53</td>\n      <td>28610</td>\n      <td>97.22175</td>\n      <td>0.195954</td>\n      <td>97.613659</td>\n      <td>96.829841</td>\n      <td>97.20</td>\n      <td>...</td>\n      <td>97.22175</td>\n      <td>97.581698</td>\n      <td>96.861802</td>\n      <td>97.210416</td>\n      <td>97.216466</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2018-12-31</th>\n      <td>97.62</td>\n      <td>97.730</td>\n      <td>96.850</td>\n      <td>97.73</td>\n      <td>91056</td>\n      <td>97.23225</td>\n      <td>0.217246</td>\n      <td>97.666743</td>\n      <td>96.797757</td>\n      <td>97.53</td>\n      <td>...</td>\n      <td>97.23225</td>\n      <td>97.629345</td>\n      <td>96.835155</td>\n      <td>97.314333</td>\n      <td>97.263151</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>12909 rows × 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "response_data = lib_copy.signals_generator(everything)\n",
    "\n",
    "response_data.index = response_data.index.date\n",
    "final_df = response_data\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "\"practice logic\\n\\nmerge actual cross and actual squeeze DF's\\ncarolina's_df = pd.Concatenate(ewma_cross, squeeze)\\n\\nfeed merged df into jonathans target function using 1+1 = 2 target mechanism\\n\\nuse lstm model: utilizing the squeeze and the ewma cross as features and the target as the target\\n\\nspit out graph\\n\\n\""
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "\"\"\"practice logic\n",
    "\n",
    "merge actual cross and actual squeeze DF's\n",
    "carolina's_df = pd.Concatenate(ewma_cross, squeeze)\n",
    "\n",
    "feed merged df into jonathans target function using 1+1 = 2 target mechanism\n",
    "\n",
    "use lstm model: utilizing the squeeze and the ewma cross as features and the target as the target\n",
    "\n",
    "spit out graph\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.iloc[:, 0:20].values\n",
    "y = final_df.iloc[:, -1].values\n",
    "\n",
    "X, y = np.array(X), np.array(y).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X sample values:\n[[8.67400000e+01 8.68200000e+01 8.67300000e+01 8.68000000e+01\n  1.84570000e+04 8.66697500e+01 2.15116095e-01 8.70999822e+01\n  8.62395178e+01 8.67500000e+01 9.00000000e-02 2.03310546e-01\n  2.03310546e-01 8.66697500e+01 8.68730605e+01 8.64664395e+01\n  8.67134785e+01 8.66610306e+01 0.00000000e+00 0.00000000e+00]\n [8.68100000e+01 8.68750000e+01 8.67800000e+01 8.68100000e+01\n  2.46080000e+04 8.66857500e+01 2.12932377e-01 8.71116148e+01\n  8.62598852e+01 8.68000000e+01 9.50000000e-02 1.93300280e-01\n  1.93300280e-01 8.66857500e+01 8.68790503e+01 8.64924497e+01\n  8.67327828e+01 8.66745733e+01 0.00000000e+00 0.00000000e+00]\n [8.68100000e+01 8.68600000e+01 8.67700000e+01 8.68600000e+01\n  1.41590000e+04 8.67095000e+01 2.03921424e-01 8.71173428e+01\n  8.63016572e+01 8.68100000e+01 9.00000000e-02 1.83949379e-01\n  1.83949379e-01 8.67095000e+01 8.68934494e+01 8.65255506e+01\n  8.67582263e+01 8.66914303e+01 0.00000000e+00 0.00000000e+00]] \n\nX sample values:\n[[0.]\n [0.]\n [0.]] \n\n"
    }
   ],
   "source": [
    "print (f\"X sample values:\\n{X[:3]} \\n\")\n",
    "print (f\"X sample values:\\n{y[:3]} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually splitting the data\n",
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the MinMaxScaler from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the features data X\n",
    "scaler.fit(X)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the target data Y\n",
    "scaler.fit(y)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X_train sample values:\n[[[0.13535838]\n  [0.13263944]\n  [0.13605988]\n  [0.13733333]\n  [0.00847517]\n  [0.12658606]\n  [0.06388187]\n  [0.12829974]\n  [0.13547584]\n  [0.136     ]\n  [0.01215395]\n  [0.07063382]\n  [0.07063382]\n  [0.12658606]\n  [0.12511733]\n  [0.12803312]\n  [0.12986483]\n  [0.12346498]\n  [0.        ]\n  [0.        ]]\n\n [[0.13722355]\n  [0.13410729]\n  [0.13739642]\n  [0.1376    ]\n  [0.011315  ]\n  [0.12702008]\n  [0.06296816]\n  [0.12861294]\n  [0.13602141]\n  [0.13733333]\n  [0.01282917]\n  [0.06365782]\n  [0.06365782]\n  [0.12702008]\n  [0.12527965]\n  [0.12873816]\n  [0.13038519]\n  [0.12383502]\n  [0.        ]\n  [0.        ]]\n\n [[0.13722355]\n  [0.13370697]\n  [0.13712911]\n  [0.13893333]\n  [0.00649084]\n  [0.12766434]\n  [0.05919781]\n  [0.12876717]\n  [0.13714033]\n  [0.1376    ]\n  [0.01215395]\n  [0.05714132]\n  [0.05714132]\n  [0.12766434]\n  [0.12566984]\n  [0.1296354 ]\n  [0.13107103]\n  [0.12429562]\n  [0.        ]\n  [0.        ]]] \n\nX_test sample values:\n[[[0.80309086]\n  [0.80330931]\n  [0.8045977 ]\n  [0.80693333]\n  [0.00809566]\n  [0.81405427]\n  [0.24462601]\n  [0.83390708]\n  [0.79118344]\n  [0.80373333]\n  [0.02835922]\n  [0.13047742]\n  [0.13047742]\n  [0.81405427]\n  [0.81420677]\n  [0.81265798]\n  [0.80626436]\n  [0.81919021]\n  [0.        ]\n  [0.        ]]\n\n [[0.80602185]\n  [0.8049106 ]\n  [0.80673617]\n  [0.80506667]\n  [0.00686527]\n  [0.81185702]\n  [0.20424899]\n  [0.82652984]\n  [0.79418348]\n  [0.80693333]\n  [0.02565834]\n  [0.12554031]\n  [0.12554031]\n  [0.81185702]\n  [0.8118198 ]\n  [0.81065442]\n  [0.80644495]\n  [0.8184875 ]\n  [0.        ]\n  [0.        ]]\n\n [[0.80468958]\n  [0.80704564]\n  [0.80513232]\n  [0.80853333]\n  [0.00854396]\n  [0.81010735]\n  [0.16377644]\n  [0.81958455]\n  [0.79763772]\n  [0.80506667]\n  [0.04456448]\n  [0.1279247 ]\n  [0.1279247 ]\n  [0.81010735]\n  [0.81016465]\n  [0.80881332]\n  [0.80729028]\n  [0.81817159]\n  [0.        ]\n  [0.        ]]]\n"
    }
   ],
   "source": [
    "# Reshape the features data\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Print some sample data after reshaping the datasets\n",
    "print (f\"X_train sample values:\\n{X_train[:3]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model setup\n",
    "number_units = 30\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nlstm (LSTM)                  (None, 20, 30)            3840      \n_________________________________________________________________\ndropout (Dropout)            (None, 20, 30)            0         \n_________________________________________________________________\nlstm_1 (LSTM)                (None, 20, 30)            7320      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 20, 30)            0         \n_________________________________________________________________\nlstm_2 (LSTM)                (None, 30)                7320      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 30)                0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 31        \n=================================================================\nTotal params: 18,511\nTrainable params: 18,511\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "# Show the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n101/101 [==============================] - 8s 77ms/step - loss: 0.0152\nEpoch 2/10\n101/101 [==============================] - 8s 77ms/step - loss: 0.0079\nEpoch 3/10\n101/101 [==============================] - 7s 73ms/step - loss: 0.0069\nEpoch 4/10\n101/101 [==============================] - 7s 66ms/step - loss: 0.0068\nEpoch 5/10\n101/101 [==============================] - 7s 65ms/step - loss: 0.0066\nEpoch 6/10\n101/101 [==============================] - 7s 65ms/step - loss: 0.0065\nEpoch 7/10\n101/101 [==============================] - 7s 66ms/step - loss: 0.0063\nEpoch 8/10\n101/101 [==============================] - 6s 64ms/step - loss: 0.0062\nEpoch 9/10\n101/101 [==============================] - 7s 66ms/step - loss: 0.0059\nEpoch 10/10\n101/101 [==============================] - 6s 63ms/step - loss: 0.0051\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x147485400>"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=90, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0051147365011274815"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing data X_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "            Actual  Predicted\n2018-05-23     0.0  -0.092754\n2018-05-23     0.0  -0.091606\n2018-05-23     0.0  -0.093384\n2018-05-23     0.0  -0.092462\n2018-05-23     0.0  -0.091678",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Actual</th>\n      <th>Predicted</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2018-05-23</th>\n      <td>0.0</td>\n      <td>-0.092754</td>\n    </tr>\n    <tr>\n      <th>2018-05-23</th>\n      <td>0.0</td>\n      <td>-0.091606</td>\n    </tr>\n    <tr>\n      <th>2018-05-23</th>\n      <td>0.0</td>\n      <td>-0.093384</td>\n    </tr>\n    <tr>\n      <th>2018-05-23</th>\n      <td>0.0</td>\n      <td>-0.092462</td>\n    </tr>\n    <tr>\n      <th>2018-05-23</th>\n      <td>0.0</td>\n      <td>-0.091678</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Actual\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = final_df.index[-len(real_prices): ]) \n",
    "\n",
    "# Show the DataFrame's head\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<matplotlib.axes._subplots.AxesSubplot at 0x119d2e9d0>"
     },
     "metadata": {},
     "execution_count": 30
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"263.63625pt\" version=\"1.1\" viewBox=\"0 0 387.527044 263.63625\" width=\"387.527044pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M -0 263.63625 \nL 387.527044 263.63625 \nL 387.527044 0 \nL -0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 38.482813 239.758125 \nL 373.282813 239.758125 \nL 373.282813 22.318125 \nL 38.482813 22.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m428530832d\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"66.040061\" xlink:href=\"#m428530832d\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 2018-06 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n       <path d=\"M 4.890625 31.390625 \nL 31.203125 31.390625 \nL 31.203125 23.390625 \nL 4.890625 23.390625 \nz\n\" id=\"DejaVuSans-45\"/>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(45.148654 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-45\"/>\n       <use x=\"290.576172\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"354.199219\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"107.170282\" xlink:href=\"#m428530832d\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2018-07 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(86.278876 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-45\"/>\n       <use x=\"290.576172\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"354.199219\" xlink:href=\"#DejaVuSans-55\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"149.67151\" xlink:href=\"#m428530832d\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 2018-08 -->\n      <g transform=\"translate(128.780104 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-45\"/>\n       <use x=\"290.576172\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"354.199219\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"192.172739\" xlink:href=\"#m428530832d\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 2018-09 -->\n      <defs>\n       <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n      </defs>\n      <g transform=\"translate(171.281333 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-45\"/>\n       <use x=\"290.576172\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"354.199219\" xlink:href=\"#DejaVuSans-57\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"233.30296\" xlink:href=\"#m428530832d\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2018-10 -->\n      <g transform=\"translate(212.411554 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-45\"/>\n       <use x=\"290.576172\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"354.199219\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"275.804188\" xlink:href=\"#m428530832d\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2018-11 -->\n      <g transform=\"translate(254.912782 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-45\"/>\n       <use x=\"290.576172\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"354.199219\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"316.93441\" xlink:href=\"#m428530832d\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 2018-12 -->\n      <g transform=\"translate(296.043003 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-45\"/>\n       <use x=\"290.576172\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"354.199219\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"359.435638\" xlink:href=\"#m428530832d\" y=\"239.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2019-01 -->\n      <g transform=\"translate(338.544232 254.356563)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-57\"/>\n       <use x=\"254.492188\" xlink:href=\"#DejaVuSans-45\"/>\n       <use x=\"290.576172\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"354.199219\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m6b0d0eb459\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m6b0d0eb459\" y=\"229.874489\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- −1.0 -->\n      <defs>\n       <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 233.673707)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m6b0d0eb459\" y=\"196.929034\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- −0.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 200.728253)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"147.412109\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"179.199219\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m6b0d0eb459\" y=\"163.98358\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.0 -->\n      <g transform=\"translate(15.579688 167.782798)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m6b0d0eb459\" y=\"131.038125\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.5 -->\n      <g transform=\"translate(15.579688 134.837344)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m6b0d0eb459\" y=\"98.09267\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.0 -->\n      <g transform=\"translate(15.579688 101.891889)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m6b0d0eb459\" y=\"65.147216\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.5 -->\n      <g transform=\"translate(15.579688 68.946435)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"38.482813\" xlink:href=\"#m6b0d0eb459\" y=\"32.201761\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 2.0 -->\n      <g transform=\"translate(15.579688 36.00098)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pc853ed9df6)\" d=\"M 53.700994 163.98358 \nL 53.700994 98.09267 \nL 55.072002 229.874489 \nL 55.072002 98.09267 \nL 55.072002 163.98358 \nL 56.443009 229.874489 \nL 56.443009 163.98358 \nL 56.443009 163.98358 \nL 63.298046 163.98358 \nL 63.298046 163.98358 \nL 63.298046 98.09267 \nL 63.298046 163.98358 \nL 64.669053 163.98358 \nL 64.669053 163.98358 \nL 64.669053 229.874489 \nL 64.669053 163.98358 \nL 66.040061 98.09267 \nL 66.040061 163.98358 \nL 66.040061 163.98358 \nL 70.153083 163.98358 \nL 70.153083 163.98358 \nL 70.153083 229.874489 \nL 70.153083 98.09267 \nL 70.153083 98.09267 \nL 71.52409 163.98358 \nL 71.52409 163.98358 \nL 71.52409 98.09267 \nL 71.52409 163.98358 \nL 79.750134 163.98358 \nL 79.750134 163.98358 \nL 79.750134 229.874489 \nL 79.750134 163.98358 \nL 82.492149 163.98358 \nL 82.492149 163.98358 \nL 82.492149 98.09267 \nL 82.492149 163.98358 \nL 83.863156 163.98358 \nL 83.863156 229.874489 \nL 83.863156 163.98358 \nL 85.234164 163.98358 \nL 85.234164 163.98358 \nL 85.234164 98.09267 \nL 85.234164 163.98358 \nL 89.347186 163.98358 \nL 89.347186 163.98358 \nL 90.718193 229.874489 \nL 90.718193 98.09267 \nL 90.718193 163.98358 \nL 92.089201 163.98358 \nL 92.089201 163.98358 \nL 92.089201 229.874489 \nL 92.089201 163.98358 \nL 93.460208 163.98358 \nL 93.460208 163.98358 \nL 93.460208 98.09267 \nL 93.460208 163.98358 \nL 94.831215 163.98358 \nL 94.831215 163.98358 \nL 94.831215 229.874489 \nL 94.831215 163.98358 \nL 100.315245 163.98358 \nL 100.315245 163.98358 \nL 100.315245 98.09267 \nL 100.315245 163.98358 \nL 101.686252 163.98358 \nL 101.686252 163.98358 \nL 101.686252 229.874489 \nL 101.686252 163.98358 \nL 103.05726 163.98358 \nL 103.05726 163.98358 \nL 103.05726 98.09267 \nL 103.05726 163.98358 \nL 104.428267 163.98358 \nL 104.428267 163.98358 \nL 104.428267 229.874489 \nL 104.428267 163.98358 \nL 108.541289 163.98358 \nL 108.541289 163.98358 \nL 108.541289 98.09267 \nL 108.541289 163.98358 \nL 109.912297 163.98358 \nL 109.912297 163.98358 \nL 109.912297 229.874489 \nL 109.912297 163.98358 \nL 112.654311 163.98358 \nL 112.654311 163.98358 \nL 112.654311 98.09267 \nL 112.654311 163.98358 \nL 114.025319 163.98358 \nL 114.025319 163.98358 \nL 114.025319 98.09267 \nL 114.025319 229.874489 \nL 118.138341 98.09267 \nL 118.138341 163.98358 \nL 118.138341 163.98358 \nL 119.509348 163.98358 \nL 119.509348 163.98358 \nL 119.509348 229.874489 \nL 119.509348 163.98358 \nL 120.880355 163.98358 \nL 120.880355 163.98358 \nL 120.880355 98.09267 \nL 120.880355 229.874489 \nL 120.880355 163.98358 \nL 122.251363 163.98358 \nL 122.251363 163.98358 \nL 122.251363 98.09267 \nL 122.251363 163.98358 \nL 123.62237 163.98358 \nL 123.62237 163.98358 \nL 123.62237 229.874489 \nL 123.62237 98.09267 \nL 123.62237 163.98358 \nL 127.735392 98.09267 \nL 127.735392 163.98358 \nL 127.735392 163.98358 \nL 131.848414 163.98358 \nL 131.848414 229.874489 \nL 131.848414 163.98358 \nL 133.219422 163.98358 \nL 133.219422 163.98358 \nL 133.219422 98.09267 \nL 133.219422 163.98358 \nL 138.703451 163.98358 \nL 138.703451 163.98358 \nL 138.703451 229.874489 \nL 138.703451 163.98358 \nL 140.074459 163.98358 \nL 140.074459 163.98358 \nL 140.074459 98.09267 \nL 140.074459 163.98358 \nL 141.445466 163.98358 \nL 141.445466 163.98358 \nL 141.445466 229.874489 \nL 141.445466 163.98358 \nL 142.816473 98.09267 \nL 142.816473 229.874489 \nL 142.816473 163.98358 \nL 146.929496 163.98358 \nL 146.929496 163.98358 \nL 148.300503 229.874489 \nL 148.300503 163.98358 \nL 148.300503 163.98358 \nL 149.67151 163.98358 \nL 149.67151 163.98358 \nL 149.67151 98.09267 \nL 149.67151 229.874489 \nL 149.67151 163.98358 \nL 156.526547 163.98358 \nL 156.526547 163.98358 \nL 156.526547 229.874489 \nL 156.526547 98.09267 \nL 156.526547 163.98358 \nL 157.897555 163.98358 \nL 157.897555 163.98358 \nL 157.897555 229.874489 \nL 157.897555 163.98358 \nL 159.268562 163.98358 \nL 159.268562 98.09267 \nL 159.268562 163.98358 \nL 160.639569 229.874489 \nL 160.639569 98.09267 \nL 162.010577 163.98358 \nL 162.010577 163.98358 \nL 167.494606 163.98358 \nL 167.494606 163.98358 \nL 167.494606 98.09267 \nL 167.494606 163.98358 \nL 168.865613 163.98358 \nL 168.865613 229.874489 \nL 168.865613 163.98358 \nL 170.236621 98.09267 \nL 170.236621 163.98358 \nL 170.236621 163.98358 \nL 171.607628 163.98358 \nL 171.607628 229.874489 \nL 171.607628 98.09267 \nL 171.607628 163.98358 \nL 175.72065 163.98358 \nL 175.72065 163.98358 \nL 175.72065 229.874489 \nL 175.72065 98.09267 \nL 177.091658 163.98358 \nL 177.091658 163.98358 \nL 177.091658 229.874489 \nL 177.091658 163.98358 \nL 181.20468 163.98358 \nL 181.20468 98.09267 \nL 181.20468 229.874489 \nL 181.20468 163.98358 \nL 185.317702 98.09267 \nL 185.317702 163.98358 \nL 185.317702 163.98358 \nL 186.688709 163.98358 \nL 186.688709 163.98358 \nL 186.688709 229.874489 \nL 186.688709 163.98358 \nL 189.430724 163.98358 \nL 189.430724 163.98358 \nL 189.430724 98.09267 \nL 189.430724 163.98358 \nL 196.285761 163.98358 \nL 196.285761 163.98358 \nL 196.285761 98.09267 \nL 196.285761 163.98358 \nL 197.656768 163.98358 \nL 197.656768 163.98358 \nL 197.656768 229.874489 \nL 197.656768 163.98358 \nL 199.027776 163.98358 \nL 199.027776 163.98358 \nL 200.398783 98.09267 \nL 200.398783 229.874489 \nL 200.398783 163.98358 \nL 204.511805 163.98358 \nL 204.511805 163.98358 \nL 204.511805 229.874489 \nL 204.511805 163.98358 \nL 205.882812 163.98358 \nL 205.882812 163.98358 \nL 205.882812 98.09267 \nL 205.882812 163.98358 \nL 207.25382 163.98358 \nL 207.25382 163.98358 \nL 207.25382 98.09267 \nL 207.25382 229.874489 \nL 207.25382 163.98358 \nL 208.624827 163.98358 \nL 208.624827 163.98358 \nL 208.624827 98.09267 \nL 208.624827 229.874489 \nL 208.624827 163.98358 \nL 209.995835 163.98358 \nL 209.995835 163.98358 \nL 209.995835 229.874489 \nL 209.995835 163.98358 \nL 214.108857 98.09267 \nL 214.108857 229.874489 \nL 214.108857 163.98358 \nL 215.479864 163.98358 \nL 215.479864 163.98358 \nL 215.479864 98.09267 \nL 216.850871 163.98358 \nL 216.850871 163.98358 \nL 219.592886 163.98358 \nL 219.592886 163.98358 \nL 219.592886 229.874489 \nL 219.592886 163.98358 \nL 225.076916 163.98358 \nL 225.076916 163.98358 \nL 225.076916 98.09267 \nL 225.076916 229.874489 \nL 225.076916 163.98358 \nL 227.81893 163.98358 \nL 227.81893 163.98358 \nL 227.81893 98.09267 \nL 227.81893 229.874489 \nL 227.81893 163.98358 \nL 233.30296 163.98358 \nL 233.30296 163.98358 \nL 233.30296 98.09267 \nL 233.30296 229.874489 \nL 233.30296 163.98358 \nL 234.673967 163.98358 \nL 234.673967 98.09267 \nL 234.673967 163.98358 \nL 237.415982 163.98358 \nL 237.415982 163.98358 \nL 237.415982 229.874489 \nL 237.415982 98.09267 \nL 238.786989 163.98358 \nL 238.786989 163.98358 \nL 238.786989 229.874489 \nL 238.786989 163.98358 \nL 242.900012 163.98358 \nL 242.900012 163.98358 \nL 242.900012 98.09267 \nL 242.900012 163.98358 \nL 244.271019 163.98358 \nL 244.271019 163.98358 \nL 244.271019 229.874489 \nL 244.271019 98.09267 \nL 244.271019 163.98358 \nL 245.642026 163.98358 \nL 245.642026 98.09267 \nL 245.642026 163.98358 \nL 252.497063 163.98358 \nL 252.497063 98.09267 \nL 252.497063 229.874489 \nL 252.497063 163.98358 \nL 253.86807 163.98358 \nL 253.86807 163.98358 \nL 253.86807 98.09267 \nL 253.86807 163.98358 \nL 256.610085 163.98358 \nL 256.610085 229.874489 \nL 256.610085 163.98358 \nL 257.981093 163.98358 \nL 257.981093 163.98358 \nL 257.981093 98.09267 \nL 257.981093 229.874489 \nL 257.981093 163.98358 \nL 263.465122 163.98358 \nL 263.465122 163.98358 \nL 263.465122 98.09267 \nL 263.465122 163.98358 \nL 264.836129 229.874489 \nL 264.836129 98.09267 \nL 264.836129 163.98358 \nL 266.207137 163.98358 \nL 266.207137 163.98358 \nL 266.207137 98.09267 \nL 266.207137 163.98358 \nL 267.578144 229.874489 \nL 267.578144 163.98358 \nL 267.578144 163.98358 \nL 271.691166 163.98358 \nL 271.691166 98.09267 \nL 271.691166 229.874489 \nL 271.691166 163.98358 \nL 273.062174 163.98358 \nL 273.062174 163.98358 \nL 273.062174 98.09267 \nL 273.062174 229.874489 \nL 273.062174 163.98358 \nL 275.804188 163.98358 \nL 275.804188 163.98358 \nL 275.804188 229.874489 \nL 275.804188 163.98358 \nL 277.175196 98.09267 \nL 277.175196 229.874489 \nL 277.175196 163.98358 \nL 281.288218 163.98358 \nL 281.288218 98.09267 \nL 281.288218 163.98358 \nL 282.659225 229.874489 \nL 282.659225 98.09267 \nL 282.659225 163.98358 \nL 286.772247 163.98358 \nL 286.772247 229.874489 \nL 286.772247 163.98358 \nL 292.256277 163.98358 \nL 292.256277 163.98358 \nL 292.256277 98.09267 \nL 292.256277 229.874489 \nL 292.256277 163.98358 \nL 293.627284 163.98358 \nL 293.627284 98.09267 \nL 293.627284 229.874489 \nL 293.627284 163.98358 \nL 294.998292 163.98358 \nL 294.998292 98.09267 \nL 294.998292 163.98358 \nL 296.369299 163.98358 \nL 296.369299 163.98358 \nL 296.369299 98.09267 \nL 296.369299 98.09267 \nL 300.482321 98.09267 \nL 300.482321 229.874489 \nL 300.482321 163.98358 \nL 301.853328 163.98358 \nL 301.853328 229.874489 \nL 301.853328 163.98358 \nL 303.224336 163.98358 \nL 303.224336 163.98358 \nL 303.224336 98.09267 \nL 303.224336 229.874489 \nL 303.224336 163.98358 \nL 310.079373 163.98358 \nL 310.079373 163.98358 \nL 310.079373 98.09267 \nL 310.079373 163.98358 \nL 311.45038 163.98358 \nL 311.45038 163.98358 \nL 311.45038 98.09267 \nL 311.45038 163.98358 \nL 312.821387 163.98358 \nL 312.821387 163.98358 \nL 312.821387 229.874489 \nL 312.821387 98.09267 \nL 312.821387 163.98358 \nL 314.192395 163.98358 \nL 314.192395 163.98358 \nL 314.192395 229.874489 \nL 314.192395 98.09267 \nL 314.192395 163.98358 \nL 315.563402 163.98358 \nL 315.563402 163.98358 \nL 315.563402 229.874489 \nL 315.563402 98.09267 \nL 315.563402 163.98358 \nL 319.676424 163.98358 \nL 319.676424 163.98358 \nL 321.047432 229.874489 \nL 321.047432 163.98358 \nL 321.047432 163.98358 \nL 323.789446 163.98358 \nL 323.789446 163.98358 \nL 325.160454 98.09267 \nL 325.160454 229.874489 \nL 325.160454 163.98358 \nL 329.273476 163.98358 \nL 329.273476 163.98358 \nL 330.644483 98.09267 \nL 330.644483 229.874489 \nL 330.644483 163.98358 \nL 332.015491 163.98358 \nL 332.015491 163.98358 \nL 332.015491 98.09267 \nL 332.015491 229.874489 \nL 333.386498 163.98358 \nL 333.386498 163.98358 \nL 333.386498 98.09267 \nL 333.386498 98.09267 \nL 334.757505 98.09267 \nL 334.757505 98.09267 \nL 334.757505 229.874489 \nL 334.757505 32.201761 \nL 334.757505 163.98358 \nL 340.241535 163.98358 \nL 340.241535 163.98358 \nL 340.241535 98.09267 \nL 340.241535 229.874489 \nL 340.241535 163.98358 \nL 341.612542 163.98358 \nL 341.612542 163.98358 \nL 341.612542 98.09267 \nL 341.612542 229.874489 \nL 341.612542 163.98358 \nL 344.354557 163.98358 \nL 344.354557 163.98358 \nL 344.354557 98.09267 \nL 344.354557 229.874489 \nL 344.354557 163.98358 \nL 351.209594 163.98358 \nL 351.209594 163.98358 \nL 351.209594 98.09267 \nL 351.209594 163.98358 \nL 352.580601 163.98358 \nL 352.580601 163.98358 \nL 352.580601 229.874489 \nL 352.580601 98.09267 \nL 352.580601 163.98358 \nL 358.064631 163.98358 \nL 358.064631 163.98358 \nL 358.064631 229.874489 \nL 358.064631 98.09267 \nL 358.064631 98.09267 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pc853ed9df6)\" d=\"M 53.700994 170.095217 \nL 53.700994 170.136744 \nL 53.700994 146.04183 \nL 55.072002 171.444611 \nL 55.072002 169.995393 \nL 55.072002 145.782239 \nL 55.072002 169.638509 \nL 56.443009 170.742037 \nL 56.443009 168.736198 \nL 56.443009 168.826073 \nL 61.927039 171.388887 \nL 61.927039 169.059372 \nL 61.927039 169.295335 \nL 63.298046 171.185379 \nL 63.298046 146.971547 \nL 63.298046 169.116958 \nL 64.669053 170.264487 \nL 64.669053 170.788082 \nL 64.669053 168.744487 \nL 64.669053 168.888525 \nL 66.040061 147.215539 \nL 66.040061 170.243667 \nL 66.040061 168.750078 \nL 70.153083 169.504976 \nL 70.153083 141.37079 \nL 71.52409 168.657693 \nL 71.52409 167.88164 \nL 71.52409 142.887243 \nL 71.52409 167.532192 \nL 74.266105 171.869265 \nL 74.266105 169.473264 \nL 74.266105 170.541852 \nL 75.637112 171.241456 \nL 75.637112 171.130179 \nL 75.637112 169.123845 \nL 79.750134 169.7665 \nL 79.750134 169.065505 \nL 79.750134 170.055305 \nL 79.750134 169.478012 \nL 81.121142 169.254262 \nL 81.121142 168.770867 \nL 81.121142 168.866009 \nL 82.492149 169.190803 \nL 82.492149 170.287633 \nL 82.492149 145.44998 \nL 82.492149 170.030303 \nL 83.863156 170.376842 \nL 83.863156 172.801957 \nL 83.863156 168.374284 \nL 83.863156 168.736251 \nL 85.234164 168.698024 \nL 85.234164 169.435084 \nL 85.234164 143.686507 \nL 85.234164 168.440512 \nL 89.347186 169.862483 \nL 89.347186 167.824738 \nL 89.347186 167.93314 \nL 90.718193 169.786877 \nL 90.718193 142.969094 \nL 90.718193 167.829092 \nL 92.089201 168.744475 \nL 92.089201 167.692129 \nL 92.089201 168.829071 \nL 92.089201 167.8664 \nL 93.460208 168.523771 \nL 93.460208 168.489414 \nL 93.460208 143.322448 \nL 93.460208 168.450226 \nL 94.831215 169.293791 \nL 94.831215 169.639535 \nL 94.831215 167.671923 \nL 94.831215 168.21946 \nL 98.944238 169.060327 \nL 98.944238 168.970423 \nL 98.944238 168.169851 \nL 98.944238 169.161948 \nL 98.944238 168.755821 \nL 100.315245 170.613393 \nL 100.315245 144.149318 \nL 100.315245 167.848892 \nL 101.686252 168.059157 \nL 101.686252 169.344437 \nL 101.686252 168.543041 \nL 103.05726 169.868127 \nL 103.05726 169.71391 \nL 103.05726 145.89883 \nL 103.05726 170.28031 \nL 104.428267 169.548847 \nL 104.428267 170.414739 \nL 104.428267 168.502545 \nL 104.428267 169.156375 \nL 108.541289 169.954349 \nL 108.541289 142.671852 \nL 108.541289 167.392631 \nL 109.912297 167.967362 \nL 109.912297 168.40186 \nL 109.912297 167.797609 \nL 109.912297 168.370101 \nL 112.654311 168.127458 \nL 112.654311 168.862998 \nL 112.654311 140.423347 \nL 112.654311 167.177677 \nL 114.025319 169.403348 \nL 114.025319 143.634506 \nL 114.025319 166.729758 \nL 118.138341 145.272953 \nL 118.138341 168.152201 \nL 118.138341 167.721885 \nL 119.509348 167.931332 \nL 119.509348 167.361438 \nL 119.509348 168.708757 \nL 119.509348 167.4585 \nL 120.880355 167.552457 \nL 120.880355 168.069696 \nL 120.880355 142.768178 \nL 120.880355 167.678556 \nL 122.251363 168.919759 \nL 122.251363 143.316357 \nL 122.251363 167.815925 \nL 123.62237 168.248768 \nL 123.62237 146.831015 \nL 123.62237 171.916318 \nL 123.62237 168.82103 \nL 127.735392 147.770699 \nL 127.735392 170.074104 \nL 127.735392 169.553954 \nL 129.1064 170.92422 \nL 129.1064 170.768141 \nL 129.1064 169.646415 \nL 129.1064 169.744979 \nL 131.848414 170.206524 \nL 131.848414 170.779134 \nL 131.848414 169.400008 \nL 133.219422 169.415295 \nL 133.219422 169.345674 \nL 133.219422 170.532956 \nL 133.219422 145.821067 \nL 133.219422 169.492027 \nL 137.332444 171.041011 \nL 137.332444 170.013225 \nL 137.332444 170.913204 \nL 138.703451 171.699925 \nL 138.703451 171.686564 \nL 138.703451 171.02451 \nL 138.703451 171.791503 \nL 138.703451 171.183081 \nL 140.074459 171.599765 \nL 140.074459 171.558339 \nL 140.074459 171.813983 \nL 140.074459 148.233004 \nL 140.074459 171.661816 \nL 141.445466 171.859227 \nL 141.445466 171.824328 \nL 141.445466 172.081975 \nL 141.445466 171.383078 \nL 141.445466 171.534002 \nL 142.816473 148.831964 \nL 142.816473 172.245778 \nL 142.816473 148.755951 \nL 142.816473 171.555045 \nL 146.929496 172.352147 \nL 146.929496 173.116248 \nL 146.929496 172.767258 \nL 148.300503 173.648432 \nL 148.300503 173.573763 \nL 148.300503 173.803133 \nL 148.300503 171.765611 \nL 149.67151 173.472854 \nL 149.67151 173.465578 \nL 149.67151 149.506714 \nL 149.67151 172.597919 \nL 152.413525 173.285369 \nL 152.413525 171.690582 \nL 152.413525 171.773376 \nL 156.526547 172.653254 \nL 156.526547 172.642585 \nL 156.526547 149.159198 \nL 156.526547 171.773547 \nL 157.897555 172.579515 \nL 157.897555 172.490488 \nL 157.897555 172.293225 \nL 157.897555 172.533806 \nL 157.897555 172.428308 \nL 159.268562 173.024564 \nL 159.268562 149.548994 \nL 159.268562 172.426428 \nL 160.639569 173.010779 \nL 160.639569 146.993032 \nL 162.010577 174.031643 \nL 162.010577 171.920047 \nL 162.010577 171.810319 \nL 162.010577 172.172056 \nL 162.010577 171.826696 \nL 166.123599 172.487284 \nL 166.123599 172.741444 \nL 166.123599 171.469518 \nL 167.494606 172.012755 \nL 167.494606 146.968949 \nL 167.494606 170.79534 \nL 168.865613 171.916836 \nL 168.865613 171.913431 \nL 168.865613 171.165649 \nL 168.865613 172.054817 \nL 168.865613 171.280325 \nL 170.236621 149.452245 \nL 170.236621 172.063195 \nL 170.236621 171.085819 \nL 171.607628 171.458166 \nL 171.607628 171.454885 \nL 171.607628 146.709617 \nL 171.607628 170.608946 \nL 175.72065 171.530421 \nL 175.72065 171.557319 \nL 175.72065 146.112129 \nL 177.091658 171.701622 \nL 177.091658 171.528076 \nL 178.462665 171.980666 \nL 178.462665 171.886603 \nL 178.462665 170.421066 \nL 178.462665 170.664988 \nL 179.833672 170.96544 \nL 179.833672 171.112953 \nL 179.833672 170.200427 \nL 179.833672 170.214294 \nL 181.20468 170.667026 \nL 181.20468 146.550404 \nL 181.20468 170.949599 \nL 181.20468 170.183649 \nL 185.317702 147.313596 \nL 185.317702 171.926927 \nL 185.317702 171.915481 \nL 186.688709 172.314061 \nL 186.688709 172.192304 \nL 186.688709 171.311908 \nL 186.688709 172.205424 \nL 186.688709 171.398336 \nL 188.059717 172.07361 \nL 188.059717 171.079321 \nL 188.059717 171.310099 \nL 189.430724 171.769706 \nL 189.430724 171.704697 \nL 189.430724 146.853136 \nL 189.430724 171.768957 \nL 189.430724 171.168394 \nL 190.801731 172.339582 \nL 190.801731 170.420772 \nL 190.801731 170.439994 \nL 196.285761 171.493902 \nL 196.285761 147.49747 \nL 196.285761 171.582875 \nL 196.285761 170.862787 \nL 197.656768 171.778737 \nL 197.656768 170.556385 \nL 197.656768 171.913348 \nL 197.656768 170.706579 \nL 199.027776 171.226392 \nL 199.027776 171.126603 \nL 199.027776 171.522721 \nL 199.027776 170.20395 \nL 200.398783 146.804134 \nL 200.398783 171.156123 \nL 200.398783 146.693758 \nL 200.398783 170.450705 \nL 204.511805 171.23041 \nL 204.511805 171.328356 \nL 204.511805 170.01597 \nL 204.511805 170.033113 \nL 205.882812 170.614689 \nL 205.882812 170.40757 \nL 205.882812 146.115552 \nL 205.882812 169.974756 \nL 207.25382 170.741219 \nL 207.25382 170.65793 \nL 207.25382 145.729714 \nL 207.25382 171.384934 \nL 207.25382 170.030309 \nL 208.624827 171.082343 \nL 208.624827 146.544607 \nL 208.624827 171.430649 \nL 208.624827 170.599561 \nL 209.995835 171.501849 \nL 209.995835 169.780338 \nL 214.108857 146.711107 \nL 214.108857 170.894953 \nL 214.108857 145.908892 \nL 214.108857 169.950226 \nL 215.479864 170.390527 \nL 215.479864 170.756777 \nL 215.479864 144.793711 \nL 216.850871 172.30387 \nL 216.850871 172.296854 \nL 218.221879 173.427522 \nL 218.221879 173.015274 \nL 218.221879 173.468818 \nL 219.592886 174.165118 \nL 219.592886 174.330057 \nL 219.592886 172.403494 \nL 219.592886 172.449309 \nL 223.705908 172.170324 \nL 223.705908 173.50357 \nL 223.705908 171.555835 \nL 225.076916 172.396125 \nL 225.076916 172.955438 \nL 225.076916 149.357887 \nL 225.076916 171.959729 \nL 226.447923 172.176045 \nL 226.447923 172.067554 \nL 226.447923 171.409541 \nL 226.447923 172.34886 \nL 226.447923 172.131991 \nL 227.81893 172.898695 \nL 227.81893 173.077761 \nL 227.81893 148.205192 \nL 227.81893 171.846101 \nL 229.189938 172.96702 \nL 229.189938 170.350662 \nL 229.189938 170.532267 \nL 233.30296 171.381912 \nL 233.30296 171.671896 \nL 233.30296 147.655964 \nL 233.30296 170.690431 \nL 234.673967 171.450761 \nL 234.673967 146.253975 \nL 234.673967 170.262466 \nL 236.044975 171.501242 \nL 236.044975 171.18549 \nL 236.044975 172.219221 \nL 236.044975 171.936129 \nL 237.415982 173.548366 \nL 237.415982 173.397459 \nL 237.415982 173.899706 \nL 237.415982 149.012244 \nL 238.786989 173.6585 \nL 238.786989 171.809641 \nL 242.900012 172.401703 \nL 242.900012 172.758598 \nL 242.900012 149.451514 \nL 242.900012 171.879704 \nL 244.271019 173.360811 \nL 244.271019 173.295985 \nL 244.271019 149.691241 \nL 244.271019 173.336687 \nL 244.271019 171.556842 \nL 245.642026 146.950221 \nL 245.642026 147.633701 \nL 245.642026 173.12747 \nL 247.013034 173.426126 \nL 247.013034 174.66324 \nL 247.013034 172.653648 \nL 247.013034 173.596007 \nL 248.384041 175.131424 \nL 248.384041 176.820687 \nL 248.384041 172.475984 \nL 252.497063 174.140128 \nL 252.497063 147.968835 \nL 252.497063 171.299313 \nL 253.86807 171.980077 \nL 253.86807 171.918144 \nL 253.86807 146.370171 \nL 253.86807 169.852274 \nL 255.239078 170.52277 \nL 255.239078 170.16498 \nL 255.239078 171.209832 \nL 256.610085 172.382952 \nL 256.610085 170.447623 \nL 256.610085 170.558901 \nL 257.981093 171.229903 \nL 257.981093 171.991394 \nL 257.981093 147.356148 \nL 257.981093 170.232115 \nL 262.094115 170.771157 \nL 262.094115 171.001093 \nL 262.094115 168.57163 \nL 263.465122 170.919271 \nL 263.465122 171.448446 \nL 263.465122 145.892762 \nL 263.465122 169.734104 \nL 264.836129 170.818198 \nL 264.836129 143.119635 \nL 264.836129 170.331533 \nL 266.207137 171.349646 \nL 266.207137 147.567344 \nL 266.207137 169.621684 \nL 267.578144 171.517584 \nL 267.578144 169.843879 \nL 267.578144 171.285003 \nL 271.691166 173.409041 \nL 271.691166 145.357466 \nL 271.691166 172.792449 \nL 273.062174 172.602679 \nL 273.062174 172.960422 \nL 273.062174 146.840022 \nL 273.062174 170.157404 \nL 274.433181 171.986651 \nL 274.433181 170.214624 \nL 274.433181 171.221945 \nL 275.804188 172.173358 \nL 275.804188 169.570567 \nL 277.175196 147.811672 \nL 277.175196 171.157425 \nL 277.175196 170.263037 \nL 281.288218 170.722585 \nL 281.288218 142.56236 \nL 281.288218 168.465455 \nL 282.659225 170.088808 \nL 282.659225 145.69981 \nL 282.659225 169.688584 \nL 284.030233 171.155499 \nL 284.030233 171.508146 \nL 284.030233 169.740596 \nL 285.40124 170.959284 \nL 285.40124 170.145775 \nL 285.40124 171.166344 \nL 285.40124 170.962229 \nL 286.772247 171.647436 \nL 286.772247 170.208191 \nL 286.772247 170.509309 \nL 290.88527 170.831093 \nL 290.88527 172.854176 \nL 290.88527 169.748396 \nL 290.88527 169.836527 \nL 292.256277 170.735033 \nL 292.256277 170.698278 \nL 292.256277 172.498571 \nL 292.256277 146.808334 \nL 292.256277 171.561196 \nL 293.627284 172.4704 \nL 293.627284 148.484689 \nL 293.627284 172.275039 \nL 294.998292 174.697756 \nL 294.998292 151.032192 \nL 294.998292 172.001462 \nL 296.369299 173.559412 \nL 296.369299 144.887162 \nL 296.369299 145.080449 \nL 300.482321 145.563985 \nL 300.482321 171.566627 \nL 300.482321 171.355814 \nL 301.853328 172.722309 \nL 301.853328 173.239501 \nL 301.853328 170.782056 \nL 303.224336 171.517814 \nL 303.224336 147.624882 \nL 303.224336 169.269225 \nL 305.966351 171.094885 \nL 305.966351 169.016373 \nL 305.966351 169.238409 \nL 310.079373 170.977452 \nL 310.079373 146.367255 \nL 310.079373 169.404085 \nL 311.45038 170.217664 \nL 311.45038 143.225263 \nL 311.45038 170.335498 \nL 311.45038 169.114831 \nL 312.821387 169.6993 \nL 312.821387 169.688843 \nL 312.821387 170.770056 \nL 312.821387 145.894576 \nL 312.821387 169.920258 \nL 314.192395 171.191894 \nL 314.192395 145.198837 \nL 314.192395 171.286329 \nL 314.192395 169.599298 \nL 315.563402 170.539537 \nL 315.563402 145.2498 \nL 315.563402 169.056934 \nL 319.676424 171.078714 \nL 319.676424 170.634955 \nL 319.676424 171.242263 \nL 321.047432 172.202614 \nL 321.047432 170.89004 \nL 323.789446 175.916314 \nL 323.789446 170.859194 \nL 323.789446 171.46553 \nL 325.160454 151.325511 \nL 325.160454 174.195316 \nL 325.160454 171.522868 \nL 329.273476 172.799536 \nL 329.273476 173.338325 \nL 329.273476 169.470713 \nL 330.644483 148.507718 \nL 330.644483 170.732729 \nL 330.644483 169.573967 \nL 332.015491 171.331961 \nL 332.015491 171.274517 \nL 332.015491 147.212375 \nL 332.015491 171.781105 \nL 332.015491 169.179628 \nL 333.386498 170.079565 \nL 333.386498 170.222713 \nL 333.386498 140.469951 \nL 334.757505 143.0008 \nL 334.757505 169.302693 \nL 334.757505 103.929861 \nL 334.757505 167.660612 \nL 338.870527 169.385451 \nL 338.870527 169.309874 \nL 338.870527 168.238376 \nL 338.870527 169.017999 \nL 340.241535 169.456339 \nL 340.241535 170.635461 \nL 340.241535 145.979502 \nL 340.241535 168.232526 \nL 341.612542 169.431084 \nL 341.612542 172.520297 \nL 341.612542 144.838295 \nL 341.612542 171.547263 \nL 342.98355 172.448455 \nL 342.98355 170.378344 \nL 342.98355 171.537136 \nL 344.354557 170.88776 \nL 344.354557 172.341703 \nL 344.354557 149.366541 \nL 344.354557 170.367021 \nL 348.467579 172.099066 \nL 348.467579 172.718739 \nL 348.467579 171.385741 \nL 348.467579 171.808263 \nL 351.209594 172.605047 \nL 351.209594 147.74393 \nL 351.209594 169.990197 \nL 352.580601 170.310019 \nL 352.580601 171.77661 \nL 352.580601 147.404414 \nL 352.580601 171.767856 \nL 353.951609 171.740085 \nL 353.951609 169.533059 \nL 353.951609 170.523283 \nL 358.064631 173.01984 \nL 358.064631 144.281138 \nL 358.064631 144.281138 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 38.482813 239.758125 \nL 38.482813 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 373.282813 239.758125 \nL 373.282813 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 38.482812 239.758125 \nL 373.282813 239.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 38.482812 22.318125 \nL 373.282813 22.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"text_16\">\n    <!-- Actual Vs. Predicted  Prices -->\n    <defs>\n     <path d=\"M 34.1875 63.1875 \nL 20.796875 26.90625 \nL 47.609375 26.90625 \nz\nM 28.609375 72.90625 \nL 39.796875 72.90625 \nL 67.578125 0 \nL 57.328125 0 \nL 50.6875 18.703125 \nL 17.828125 18.703125 \nL 11.1875 0 \nL 0.78125 0 \nz\n\" id=\"DejaVuSans-65\"/>\n     <path d=\"M 48.78125 52.59375 \nL 48.78125 44.1875 \nQ 44.96875 46.296875 41.140625 47.34375 \nQ 37.3125 48.390625 33.40625 48.390625 \nQ 24.65625 48.390625 19.8125 42.84375 \nQ 14.984375 37.3125 14.984375 27.296875 \nQ 14.984375 17.28125 19.8125 11.734375 \nQ 24.65625 6.203125 33.40625 6.203125 \nQ 37.3125 6.203125 41.140625 7.25 \nQ 44.96875 8.296875 48.78125 10.40625 \nL 48.78125 2.09375 \nQ 45.015625 0.34375 40.984375 -0.53125 \nQ 36.96875 -1.421875 32.421875 -1.421875 \nQ 20.0625 -1.421875 12.78125 6.34375 \nQ 5.515625 14.109375 5.515625 27.296875 \nQ 5.515625 40.671875 12.859375 48.328125 \nQ 20.21875 56 33.015625 56 \nQ 37.15625 56 41.109375 55.140625 \nQ 45.0625 54.296875 48.78125 52.59375 \nz\n\" id=\"DejaVuSans-99\"/>\n     <path d=\"M 18.3125 70.21875 \nL 18.3125 54.6875 \nL 36.8125 54.6875 \nL 36.8125 47.703125 \nL 18.3125 47.703125 \nL 18.3125 18.015625 \nQ 18.3125 11.328125 20.140625 9.421875 \nQ 21.96875 7.515625 27.59375 7.515625 \nL 36.8125 7.515625 \nL 36.8125 0 \nL 27.59375 0 \nQ 17.1875 0 13.234375 3.875 \nQ 9.28125 7.765625 9.28125 18.015625 \nL 9.28125 47.703125 \nL 2.6875 47.703125 \nL 2.6875 54.6875 \nL 9.28125 54.6875 \nL 9.28125 70.21875 \nz\n\" id=\"DejaVuSans-116\"/>\n     <path d=\"M 8.5 21.578125 \nL 8.5 54.6875 \nL 17.484375 54.6875 \nL 17.484375 21.921875 \nQ 17.484375 14.15625 20.5 10.265625 \nQ 23.53125 6.390625 29.59375 6.390625 \nQ 36.859375 6.390625 41.078125 11.03125 \nQ 45.3125 15.671875 45.3125 23.6875 \nL 45.3125 54.6875 \nL 54.296875 54.6875 \nL 54.296875 0 \nL 45.3125 0 \nL 45.3125 8.40625 \nQ 42.046875 3.421875 37.71875 1 \nQ 33.40625 -1.421875 27.6875 -1.421875 \nQ 18.265625 -1.421875 13.375 4.4375 \nQ 8.5 10.296875 8.5 21.578125 \nz\nM 31.109375 56 \nz\n\" id=\"DejaVuSans-117\"/>\n     <path d=\"M 34.28125 27.484375 \nQ 23.390625 27.484375 19.1875 25 \nQ 14.984375 22.515625 14.984375 16.5 \nQ 14.984375 11.71875 18.140625 8.90625 \nQ 21.296875 6.109375 26.703125 6.109375 \nQ 34.1875 6.109375 38.703125 11.40625 \nQ 43.21875 16.703125 43.21875 25.484375 \nL 43.21875 27.484375 \nz\nM 52.203125 31.203125 \nL 52.203125 0 \nL 43.21875 0 \nL 43.21875 8.296875 \nQ 40.140625 3.328125 35.546875 0.953125 \nQ 30.953125 -1.421875 24.3125 -1.421875 \nQ 15.921875 -1.421875 10.953125 3.296875 \nQ 6 8.015625 6 15.921875 \nQ 6 25.140625 12.171875 29.828125 \nQ 18.359375 34.515625 30.609375 34.515625 \nL 43.21875 34.515625 \nL 43.21875 35.40625 \nQ 43.21875 41.609375 39.140625 45 \nQ 35.0625 48.390625 27.6875 48.390625 \nQ 23 48.390625 18.546875 47.265625 \nQ 14.109375 46.140625 10.015625 43.890625 \nL 10.015625 52.203125 \nQ 14.9375 54.109375 19.578125 55.046875 \nQ 24.21875 56 28.609375 56 \nQ 40.484375 56 46.34375 49.84375 \nQ 52.203125 43.703125 52.203125 31.203125 \nz\n\" id=\"DejaVuSans-97\"/>\n     <path d=\"M 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 0 \nL 9.421875 0 \nz\n\" id=\"DejaVuSans-108\"/>\n     <path id=\"DejaVuSans-32\"/>\n     <path d=\"M 28.609375 0 \nL 0.78125 72.90625 \nL 11.078125 72.90625 \nL 34.1875 11.53125 \nL 57.328125 72.90625 \nL 67.578125 72.90625 \nL 39.796875 0 \nz\n\" id=\"DejaVuSans-86\"/>\n     <path d=\"M 44.28125 53.078125 \nL 44.28125 44.578125 \nQ 40.484375 46.53125 36.375 47.5 \nQ 32.28125 48.484375 27.875 48.484375 \nQ 21.1875 48.484375 17.84375 46.4375 \nQ 14.5 44.390625 14.5 40.28125 \nQ 14.5 37.15625 16.890625 35.375 \nQ 19.28125 33.59375 26.515625 31.984375 \nL 29.59375 31.296875 \nQ 39.15625 29.25 43.1875 25.515625 \nQ 47.21875 21.78125 47.21875 15.09375 \nQ 47.21875 7.46875 41.1875 3.015625 \nQ 35.15625 -1.421875 24.609375 -1.421875 \nQ 20.21875 -1.421875 15.453125 -0.5625 \nQ 10.6875 0.296875 5.421875 2 \nL 5.421875 11.28125 \nQ 10.40625 8.6875 15.234375 7.390625 \nQ 20.0625 6.109375 24.8125 6.109375 \nQ 31.15625 6.109375 34.5625 8.28125 \nQ 37.984375 10.453125 37.984375 14.40625 \nQ 37.984375 18.0625 35.515625 20.015625 \nQ 33.0625 21.96875 24.703125 23.78125 \nL 21.578125 24.515625 \nQ 13.234375 26.265625 9.515625 29.90625 \nQ 5.8125 33.546875 5.8125 39.890625 \nQ 5.8125 47.609375 11.28125 51.796875 \nQ 16.75 56 26.8125 56 \nQ 31.78125 56 36.171875 55.265625 \nQ 40.578125 54.546875 44.28125 53.078125 \nz\n\" id=\"DejaVuSans-115\"/>\n     <path d=\"M 19.671875 64.796875 \nL 19.671875 37.40625 \nL 32.078125 37.40625 \nQ 38.96875 37.40625 42.71875 40.96875 \nQ 46.484375 44.53125 46.484375 51.125 \nQ 46.484375 57.671875 42.71875 61.234375 \nQ 38.96875 64.796875 32.078125 64.796875 \nz\nM 9.8125 72.90625 \nL 32.078125 72.90625 \nQ 44.34375 72.90625 50.609375 67.359375 \nQ 56.890625 61.8125 56.890625 51.125 \nQ 56.890625 40.328125 50.609375 34.8125 \nQ 44.34375 29.296875 32.078125 29.296875 \nL 19.671875 29.296875 \nL 19.671875 0 \nL 9.8125 0 \nz\n\" id=\"DejaVuSans-80\"/>\n     <path d=\"M 41.109375 46.296875 \nQ 39.59375 47.171875 37.8125 47.578125 \nQ 36.03125 48 33.890625 48 \nQ 26.265625 48 22.1875 43.046875 \nQ 18.109375 38.09375 18.109375 28.8125 \nL 18.109375 0 \nL 9.078125 0 \nL 9.078125 54.6875 \nL 18.109375 54.6875 \nL 18.109375 46.1875 \nQ 20.953125 51.171875 25.484375 53.578125 \nQ 30.03125 56 36.53125 56 \nQ 37.453125 56 38.578125 55.875 \nQ 39.703125 55.765625 41.0625 55.515625 \nz\n\" id=\"DejaVuSans-114\"/>\n     <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n     <path d=\"M 45.40625 46.390625 \nL 45.40625 75.984375 \nL 54.390625 75.984375 \nL 54.390625 0 \nL 45.40625 0 \nL 45.40625 8.203125 \nQ 42.578125 3.328125 38.25 0.953125 \nQ 33.9375 -1.421875 27.875 -1.421875 \nQ 17.96875 -1.421875 11.734375 6.484375 \nQ 5.515625 14.40625 5.515625 27.296875 \nQ 5.515625 40.1875 11.734375 48.09375 \nQ 17.96875 56 27.875 56 \nQ 33.9375 56 38.25 53.625 \nQ 42.578125 51.265625 45.40625 46.390625 \nz\nM 14.796875 27.296875 \nQ 14.796875 17.390625 18.875 11.75 \nQ 22.953125 6.109375 30.078125 6.109375 \nQ 37.203125 6.109375 41.296875 11.75 \nQ 45.40625 17.390625 45.40625 27.296875 \nQ 45.40625 37.203125 41.296875 42.84375 \nQ 37.203125 48.484375 30.078125 48.484375 \nQ 22.953125 48.484375 18.875 42.84375 \nQ 14.796875 37.203125 14.796875 27.296875 \nz\n\" id=\"DejaVuSans-100\"/>\n     <path d=\"M 9.421875 54.6875 \nL 18.40625 54.6875 \nL 18.40625 0 \nL 9.421875 0 \nz\nM 9.421875 75.984375 \nL 18.40625 75.984375 \nL 18.40625 64.59375 \nL 9.421875 64.59375 \nz\n\" id=\"DejaVuSans-105\"/>\n    </defs>\n    <g transform=\"translate(124.394375 16.318125)scale(0.12 -0.12)\">\n     <use xlink:href=\"#DejaVuSans-65\"/>\n     <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"121.638672\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"160.847656\" xlink:href=\"#DejaVuSans-117\"/>\n     <use x=\"224.226562\" xlink:href=\"#DejaVuSans-97\"/>\n     <use x=\"285.505859\" xlink:href=\"#DejaVuSans-108\"/>\n     <use x=\"313.289062\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"345.076172\" xlink:href=\"#DejaVuSans-86\"/>\n     <use x=\"413.484375\" xlink:href=\"#DejaVuSans-115\"/>\n     <use x=\"465.583984\" xlink:href=\"#DejaVuSans-46\"/>\n     <use x=\"497.371094\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"529.158203\" xlink:href=\"#DejaVuSans-80\"/>\n     <use x=\"587.710938\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"626.574219\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"688.097656\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"751.574219\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"779.357422\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"834.337891\" xlink:href=\"#DejaVuSans-116\"/>\n     <use x=\"873.546875\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"935.070312\" xlink:href=\"#DejaVuSans-100\"/>\n     <use x=\"998.546875\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1030.333984\" xlink:href=\"#DejaVuSans-32\"/>\n     <use x=\"1062.121094\" xlink:href=\"#DejaVuSans-80\"/>\n     <use x=\"1120.673828\" xlink:href=\"#DejaVuSans-114\"/>\n     <use x=\"1161.787109\" xlink:href=\"#DejaVuSans-105\"/>\n     <use x=\"1189.570312\" xlink:href=\"#DejaVuSans-99\"/>\n     <use x=\"1244.550781\" xlink:href=\"#DejaVuSans-101\"/>\n     <use x=\"1306.074219\" xlink:href=\"#DejaVuSans-115\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 45.482813 59.674375 \nL 124.423438 59.674375 \nQ 126.423438 59.674375 126.423438 57.674375 \nL 126.423438 29.318125 \nQ 126.423438 27.318125 124.423438 27.318125 \nL 45.482813 27.318125 \nQ 43.482813 27.318125 43.482813 29.318125 \nL 43.482813 57.674375 \nQ 43.482813 59.674375 45.482813 59.674375 \nz\n\" style=\"fill:#ffffff;opacity:0.8;stroke:#cccccc;stroke-linejoin:miter;\"/>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 47.482813 35.416562 \nL 67.482812 35.416562 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_19\"/>\n    <g id=\"text_17\">\n     <!-- Actual -->\n     <g transform=\"translate(75.482812 38.916562)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"66.658203\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"121.638672\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"160.847656\" xlink:href=\"#DejaVuSans-117\"/>\n      <use x=\"224.226562\" xlink:href=\"#DejaVuSans-97\"/>\n      <use x=\"285.505859\" xlink:href=\"#DejaVuSans-108\"/>\n     </g>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 47.482813 50.094687 \nL 67.482812 50.094687 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n    </g>\n    <g id=\"line2d_21\"/>\n    <g id=\"text_18\">\n     <!-- Predicted -->\n     <g transform=\"translate(75.482812 53.594687)scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-80\"/>\n      <use x=\"58.552734\" xlink:href=\"#DejaVuSans-114\"/>\n      <use x=\"97.416016\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"158.939453\" xlink:href=\"#DejaVuSans-100\"/>\n      <use x=\"222.416016\" xlink:href=\"#DejaVuSans-105\"/>\n      <use x=\"250.199219\" xlink:href=\"#DejaVuSans-99\"/>\n      <use x=\"305.179688\" xlink:href=\"#DejaVuSans-116\"/>\n      <use x=\"344.388672\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"405.912109\" xlink:href=\"#DejaVuSans-100\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc853ed9df6\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"38.482813\" y=\"22.318125\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Plot the real vs predicted prices as a line chart\n",
    "stocks.plot(title=\"Actual Vs. Predicted  Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Python-dotenv could not parse statement starting at line 7\nPython-dotenv could not parse statement starting at line 8\n"
    }
   ],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stockstats import StockDataFrame as sdf\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import alpaca_trade_api as tradeapi\n",
    "from pathlib import Path\n",
    "import lib_copy\n",
    "load_dotenv()\n",
    "%matplotlib inline\n",
    "\n",
    "ticker_symbol = [\"TSLA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(dataframe):\n",
    "\n",
    "    X = final_df.iloc[:, 0:20].values\n",
    "    \n",
    "    y = final_df.iloc[:, -1].values\n",
    "\n",
    "    X, y = np.array(X), np.array(y).reshape(-1,1)\n",
    "\n",
    "    # Manually splitting the data\n",
    "    split = int(0.7 * len(X))\n",
    "\n",
    "    X_train = X[: split]\n",
    "    X_test = X[split:]\n",
    "\n",
    "    y_train = y[: split]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    # Importing the MinMaxScaler from sklearn\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the MinMaxScaler object with the features data X\n",
    "    scaler.fit(X)\n",
    "\n",
    "    # Scale the features training and testing sets\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit the MinMaxScaler object with the target data Y\n",
    "    scaler.fit(y)\n",
    "\n",
    "    # Scale the target training and testing sets\n",
    "    y_train = scaler.transform(y_train)\n",
    "    y_test = scaler.transform(y_test)\n",
    "\n",
    "    # Importing required Keras modules\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "    # Define the LSTM RNN model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Initial model setup\n",
    "    number_units = 30\n",
    "    dropout_fraction = 0.2\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(LSTM(\n",
    "        units=number_units,\n",
    "        return_sequences=True,\n",
    "        input_shape=(X_train.shape[1], 1))\n",
    "        )\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(LSTM(units=number_units, return_sequences=True))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(LSTM(units=number_units))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=90, verbose=1)\n",
    "\n",
    "    # Make predictions using the testing data X_test\n",
    "    predicted = model.predict(X_test)\n",
    "\n",
    "    # Recover the original prices instead of the scaled version\n",
    "    predicted_prices = scaler.inverse_transform(predicted)\n",
    "    real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    # Create a DataFrame of Real and Predicted values\n",
    "    comparison = pd.DataFrame({\n",
    "        \"Actual\": real_prices.ravel(),\n",
    "        \"Predicted\": predicted_prices.ravel()\n",
    "    }, index = final_df.index[-len(real_prices): ]) \n",
    "\n",
    "    return model.summary(), model.evaluate(X_test, y_test, verbose=0), comparison.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'close'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-ec678d994937>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0meverything\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madding_boll_kelt_ewma_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0meverything\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-ec678d994937>\u001b[0m in \u001b[0;36madding_boll_kelt_ewma_dataframe\u001b[0;34m(dataframe)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_ohlcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madding_boll_kelt_ewma_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlib_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbollinger_band_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlib_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeltner_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mlib_copy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mewma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/schoolwork/Rice/projects/Algo-Owls/lib_copy.py\u001b[0m in \u001b[0;36mbollinger_band_generator\u001b[0;34m(dataframe_name, closing_price_column_name, bollinger_band_window, num_standard_deviation)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;31m# Calculate mean and standard deviation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mdataframe_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bollinger_band_middle'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclosing_price_column_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbollinger_band_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mdataframe_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'bollinger_band_std'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe_name\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclosing_price_column_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrolling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbollinger_band_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2797\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2799\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2800\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2847\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m         \u001b[0;31m# self.columns is a MultiIndex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m             \u001b[0mnew_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method)\u001b[0m\n\u001b[1;32m   2660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2661\u001b[0m             \u001b[0;31m# not including list here breaks some indexing, xref #30892\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2662\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_level_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2663\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_maybe_to_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_level_indexer\u001b[0;34m(self, key, level, indexer)\u001b[0m\n\u001b[1;32m   2927\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2928\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2929\u001b[0;31m             \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_loc_single_level_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2931\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlevel\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlexsort_depth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36m_get_loc_single_level_index\u001b[0;34m(self, level_index, key)\u001b[0m\n\u001b[1;32m   2596\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2598\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlevel_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'close'"
     ]
    }
   ],
   "source": [
    "dataframe = lib_copy.fetch_ohlcv(ticker_symbol)\n",
    "def adding_boll_kelt_ewma_dataframe(dataframe):\n",
    "    lib_copy.bollinger_band_generator(dataframe)\n",
    "    lib_copy.keltner_channel(dataframe)\n",
    "    lib_copy.ewma(dataframe)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "everything = adding_boll_kelt_ewma_dataframe(dataframe)\n",
    "\n",
    "everything = df.dropna()\n",
    "\n",
    "response_data = lib_copy.signals_generator(everything)\n",
    "\n",
    "response_data.index = response_data.index.date\n",
    "final_df = response_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/10\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 20]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-4c9611413155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-1ca9475714ee>\u001b[0m in \u001b[0;36mlstm\u001b[0;34m(dataframe)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# Make predictions using the testing data X_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\n        return step_function(self, iterator)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\n        outputs = model.train_step(data)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:747 train_step\n        y_pred = self(x, training=True)\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:975 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs,\n    /Users/markmurdock/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:176 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) + ' of layer ' +\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: [None, 20]\n"
     ]
    }
   ],
   "source": [
    "lstm(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python_defaultSpec_1610498663466"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}