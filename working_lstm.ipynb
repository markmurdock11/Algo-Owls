{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from stockstats import StockDataFrame as sdf\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import alpaca_trade_api as tradeapi\n",
    "from pathlib import Path\n",
    "import lib_copy\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Python-dotenv could not parse statement starting at line 7\nPython-dotenv could not parse statement starting at line 8\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = lib_copy.fetch_ohlcv(\"JPM\", \"2017-01-01\", \"2019-01-01\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_boll_kelt_ewma_dataframe(dataframe):\n",
    "    lib_copy.bollinger_band_generator(dataframe)\n",
    "    lib_copy.keltner_channel(dataframe)\n",
    "    lib_copy.ewma(dataframe)\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = adding_boll_kelt_ewma_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "61"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Looking for missing values\n",
    "everything.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                            open    high     low  close  volume  \\\n2017-01-04 12:15:00-05:00  86.74  86.820  86.730  86.80   18457   \n2017-01-04 12:30:00-05:00  86.81  86.875  86.780  86.81   24608   \n2017-01-04 12:45:00-05:00  86.81  86.860  86.770  86.86   14159   \n2017-01-04 13:00:00-05:00  86.86  86.880  86.830  86.88   12004   \n2017-01-04 13:15:00-05:00  86.89  86.890  86.811  86.87   13286   \n...                          ...     ...     ...    ...     ...   \n2018-12-31 14:45:00-05:00  97.02  97.300  97.020  97.02   14407   \n2018-12-31 15:00:00-05:00  97.04  97.290  97.000  97.12   17428   \n2018-12-31 15:15:00-05:00  97.10  97.260  96.950  97.20   20678   \n2018-12-31 15:30:00-05:00  97.21  97.560  97.200  97.53   28610   \n2018-12-31 15:45:00-05:00  97.62  97.730  96.850  97.73   91056   \n\n                           bollinger_band_middle  bollinger_band_std  \\\n2017-01-04 12:15:00-05:00               86.66975            0.215116   \n2017-01-04 12:30:00-05:00               86.68575            0.212932   \n2017-01-04 12:45:00-05:00               86.70950            0.203921   \n2017-01-04 13:00:00-05:00               86.73300            0.194452   \n2017-01-04 13:15:00-05:00               86.74500            0.195165   \n...                                          ...                 ...   \n2018-12-31 14:45:00-05:00               97.24175            0.200862   \n2018-12-31 15:00:00-05:00               97.22325            0.193705   \n2018-12-31 15:15:00-05:00               97.22025            0.193571   \n2018-12-31 15:30:00-05:00               97.22175            0.195954   \n2018-12-31 15:45:00-05:00               97.23225            0.217246   \n\n                           bollinger_band_upper  bollinger_band_lower  \\\n2017-01-04 12:15:00-05:00             87.099982             86.239518   \n2017-01-04 12:30:00-05:00             87.111615             86.259885   \n2017-01-04 12:45:00-05:00             87.117343             86.301657   \n2017-01-04 13:00:00-05:00             87.121904             86.344096   \n2017-01-04 13:15:00-05:00             87.135330             86.354670   \n...                                         ...                   ...   \n2018-12-31 14:45:00-05:00             97.643474             96.840026   \n2018-12-31 15:00:00-05:00             97.610661             96.835839   \n2018-12-31 15:15:00-05:00             97.607392             96.833108   \n2018-12-31 15:30:00-05:00             97.613659             96.829841   \n2018-12-31 15:45:00-05:00             97.666743             96.797757   \n\n                           close_-1_s     tr  tr_14_smma       atr     kcmid  \\\n2017-01-04 12:15:00-05:00       86.75  0.090    0.203311  0.203311  86.66975   \n2017-01-04 12:30:00-05:00       86.80  0.095    0.193300  0.193300  86.68575   \n2017-01-04 12:45:00-05:00       86.81  0.090    0.183949  0.183949  86.70950   \n2017-01-04 13:00:00-05:00       86.86  0.050    0.172051  0.172051  86.73300   \n2017-01-04 13:15:00-05:00       86.88  0.079    0.163927  0.163927  86.74500   \n...                               ...    ...         ...       ...       ...   \n2018-12-31 14:45:00-05:00       96.95  0.350    0.369462  0.369462  97.24175   \n2018-12-31 15:00:00-05:00       97.02  0.290    0.363786  0.363786  97.22325   \n2018-12-31 15:15:00-05:00       97.12  0.310    0.359944  0.359944  97.22025   \n2018-12-31 15:30:00-05:00       97.20  0.360    0.359948  0.359948  97.22175   \n2018-12-31 15:45:00-05:00       97.53  0.880    0.397095  0.397095  97.23225   \n\n                                kcup       kclo       EMA9      EMA21  \n2017-01-04 12:15:00-05:00  86.873061  86.466439  86.713479  86.661031  \n2017-01-04 12:30:00-05:00  86.879050  86.492450  86.732783  86.674573  \n2017-01-04 12:45:00-05:00  86.893449  86.525551  86.758226  86.691430  \n2017-01-04 13:00:00-05:00  86.905051  86.560949  86.782581  86.708573  \n2017-01-04 13:15:00-05:00  86.908927  86.581073  86.800065  86.723248  \n...                              ...        ...        ...        ...  \n2018-12-31 14:45:00-05:00  97.611212  96.872288  97.111437  97.189987  \n2018-12-31 15:00:00-05:00  97.587036  96.859464  97.113150  97.183624  \n2018-12-31 15:15:00-05:00  97.580194  96.860306  97.130520  97.185113  \n2018-12-31 15:30:00-05:00  97.581698  96.861802  97.210416  97.216466  \n2018-12-31 15:45:00-05:00  97.629345  96.835155  97.314333  97.263151  \n\n[12909 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>bollinger_band_middle</th>\n      <th>bollinger_band_std</th>\n      <th>bollinger_band_upper</th>\n      <th>bollinger_band_lower</th>\n      <th>close_-1_s</th>\n      <th>tr</th>\n      <th>tr_14_smma</th>\n      <th>atr</th>\n      <th>kcmid</th>\n      <th>kcup</th>\n      <th>kclo</th>\n      <th>EMA9</th>\n      <th>EMA21</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2017-01-04 12:15:00-05:00</th>\n      <td>86.74</td>\n      <td>86.820</td>\n      <td>86.730</td>\n      <td>86.80</td>\n      <td>18457</td>\n      <td>86.66975</td>\n      <td>0.215116</td>\n      <td>87.099982</td>\n      <td>86.239518</td>\n      <td>86.75</td>\n      <td>0.090</td>\n      <td>0.203311</td>\n      <td>0.203311</td>\n      <td>86.66975</td>\n      <td>86.873061</td>\n      <td>86.466439</td>\n      <td>86.713479</td>\n      <td>86.661031</td>\n    </tr>\n    <tr>\n      <th>2017-01-04 12:30:00-05:00</th>\n      <td>86.81</td>\n      <td>86.875</td>\n      <td>86.780</td>\n      <td>86.81</td>\n      <td>24608</td>\n      <td>86.68575</td>\n      <td>0.212932</td>\n      <td>87.111615</td>\n      <td>86.259885</td>\n      <td>86.80</td>\n      <td>0.095</td>\n      <td>0.193300</td>\n      <td>0.193300</td>\n      <td>86.68575</td>\n      <td>86.879050</td>\n      <td>86.492450</td>\n      <td>86.732783</td>\n      <td>86.674573</td>\n    </tr>\n    <tr>\n      <th>2017-01-04 12:45:00-05:00</th>\n      <td>86.81</td>\n      <td>86.860</td>\n      <td>86.770</td>\n      <td>86.86</td>\n      <td>14159</td>\n      <td>86.70950</td>\n      <td>0.203921</td>\n      <td>87.117343</td>\n      <td>86.301657</td>\n      <td>86.81</td>\n      <td>0.090</td>\n      <td>0.183949</td>\n      <td>0.183949</td>\n      <td>86.70950</td>\n      <td>86.893449</td>\n      <td>86.525551</td>\n      <td>86.758226</td>\n      <td>86.691430</td>\n    </tr>\n    <tr>\n      <th>2017-01-04 13:00:00-05:00</th>\n      <td>86.86</td>\n      <td>86.880</td>\n      <td>86.830</td>\n      <td>86.88</td>\n      <td>12004</td>\n      <td>86.73300</td>\n      <td>0.194452</td>\n      <td>87.121904</td>\n      <td>86.344096</td>\n      <td>86.86</td>\n      <td>0.050</td>\n      <td>0.172051</td>\n      <td>0.172051</td>\n      <td>86.73300</td>\n      <td>86.905051</td>\n      <td>86.560949</td>\n      <td>86.782581</td>\n      <td>86.708573</td>\n    </tr>\n    <tr>\n      <th>2017-01-04 13:15:00-05:00</th>\n      <td>86.89</td>\n      <td>86.890</td>\n      <td>86.811</td>\n      <td>86.87</td>\n      <td>13286</td>\n      <td>86.74500</td>\n      <td>0.195165</td>\n      <td>87.135330</td>\n      <td>86.354670</td>\n      <td>86.88</td>\n      <td>0.079</td>\n      <td>0.163927</td>\n      <td>0.163927</td>\n      <td>86.74500</td>\n      <td>86.908927</td>\n      <td>86.581073</td>\n      <td>86.800065</td>\n      <td>86.723248</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2018-12-31 14:45:00-05:00</th>\n      <td>97.02</td>\n      <td>97.300</td>\n      <td>97.020</td>\n      <td>97.02</td>\n      <td>14407</td>\n      <td>97.24175</td>\n      <td>0.200862</td>\n      <td>97.643474</td>\n      <td>96.840026</td>\n      <td>96.95</td>\n      <td>0.350</td>\n      <td>0.369462</td>\n      <td>0.369462</td>\n      <td>97.24175</td>\n      <td>97.611212</td>\n      <td>96.872288</td>\n      <td>97.111437</td>\n      <td>97.189987</td>\n    </tr>\n    <tr>\n      <th>2018-12-31 15:00:00-05:00</th>\n      <td>97.04</td>\n      <td>97.290</td>\n      <td>97.000</td>\n      <td>97.12</td>\n      <td>17428</td>\n      <td>97.22325</td>\n      <td>0.193705</td>\n      <td>97.610661</td>\n      <td>96.835839</td>\n      <td>97.02</td>\n      <td>0.290</td>\n      <td>0.363786</td>\n      <td>0.363786</td>\n      <td>97.22325</td>\n      <td>97.587036</td>\n      <td>96.859464</td>\n      <td>97.113150</td>\n      <td>97.183624</td>\n    </tr>\n    <tr>\n      <th>2018-12-31 15:15:00-05:00</th>\n      <td>97.10</td>\n      <td>97.260</td>\n      <td>96.950</td>\n      <td>97.20</td>\n      <td>20678</td>\n      <td>97.22025</td>\n      <td>0.193571</td>\n      <td>97.607392</td>\n      <td>96.833108</td>\n      <td>97.12</td>\n      <td>0.310</td>\n      <td>0.359944</td>\n      <td>0.359944</td>\n      <td>97.22025</td>\n      <td>97.580194</td>\n      <td>96.860306</td>\n      <td>97.130520</td>\n      <td>97.185113</td>\n    </tr>\n    <tr>\n      <th>2018-12-31 15:30:00-05:00</th>\n      <td>97.21</td>\n      <td>97.560</td>\n      <td>97.200</td>\n      <td>97.53</td>\n      <td>28610</td>\n      <td>97.22175</td>\n      <td>0.195954</td>\n      <td>97.613659</td>\n      <td>96.829841</td>\n      <td>97.20</td>\n      <td>0.360</td>\n      <td>0.359948</td>\n      <td>0.359948</td>\n      <td>97.22175</td>\n      <td>97.581698</td>\n      <td>96.861802</td>\n      <td>97.210416</td>\n      <td>97.216466</td>\n    </tr>\n    <tr>\n      <th>2018-12-31 15:45:00-05:00</th>\n      <td>97.62</td>\n      <td>97.730</td>\n      <td>96.850</td>\n      <td>97.73</td>\n      <td>91056</td>\n      <td>97.23225</td>\n      <td>0.217246</td>\n      <td>97.666743</td>\n      <td>96.797757</td>\n      <td>97.53</td>\n      <td>0.880</td>\n      <td>0.397095</td>\n      <td>0.397095</td>\n      <td>97.23225</td>\n      <td>97.629345</td>\n      <td>96.835155</td>\n      <td>97.314333</td>\n      <td>97.263151</td>\n    </tr>\n  </tbody>\n</table>\n<p>12909 rows × 18 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "# Filling missing values with the previous ones\n",
    "everything = df.dropna()\n",
    "everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_data = lib_copy.signals_generator(everything)\n",
    "\n",
    "response_data.index = response_data.index.date\n",
    "final_df = response_data\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"practice logic\n",
    "\n",
    "merge actual cross and actual squeeze DF's\n",
    "carolina's_df = pd.Concatenate(ewma_cross, squeeze)\n",
    "\n",
    "feed merged df into jonathans target function using 1+1 = 2 target mechanism\n",
    "\n",
    "use lstm model: utilizing the squeeze and the ewma cross as features and the target as the target\n",
    "\n",
    "spit out graph\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_df.iloc[:, 0:20].values\n",
    "y = final_df.iloc[:, -1].values\n",
    "\n",
    "X, y = np.array(X), np.array(y).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print (f\"X sample values:\\n{X[:3]} \\n\")\n",
    "print (f\"X sample values:\\n{y[:3]} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually splitting the data\n",
    "split = int(0.7 * len(X))\n",
    "\n",
    "X_train = X[: split]\n",
    "X_test = X[split:]\n",
    "\n",
    "y_train = y[: split]\n",
    "y_test = y[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the MinMaxScaler from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Create a MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the MinMaxScaler object with the features data X\n",
    "scaler.fit(X)\n",
    "\n",
    "# Scale the features training and testing sets\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Fit the MinMaxScaler object with the target data Y\n",
    "scaler.fit(y)\n",
    "\n",
    "# Scale the target training and testing sets\n",
    "y_train = scaler.transform(y_train)\n",
    "y_test = scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape the features data\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "# Print some sample data after reshaping the datasets\n",
    "print (f\"X_train sample values:\\n{X_train[:3]} \\n\")\n",
    "print (f\"X_test sample values:\\n{X_test[:3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required Keras modules\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model.\n",
    "model = Sequential()\n",
    "\n",
    "# Initial model setup\n",
    "number_units = 30\n",
    "dropout_fraction = 0.2\n",
    "\n",
    "# Layer 1\n",
    "model.add(LSTM(\n",
    "    units=number_units,\n",
    "    return_sequences=True,\n",
    "    input_shape=(X_train.shape[1], 1))\n",
    "    )\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=number_units, return_sequences=True))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Layer 3\n",
    "model.add(LSTM(units=number_units))\n",
    "model.add(Dropout(dropout_fraction))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Show the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=90, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using the testing data X_test\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover the original prices instead of the scaled version\n",
    "predicted_prices = scaler.inverse_transform(predicted)\n",
    "real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "stocks = pd.DataFrame({\n",
    "    \"Actual\": real_prices.ravel(),\n",
    "    \"Predicted\": predicted_prices.ravel()\n",
    "}, index = final_df.index[-len(real_prices): ]) \n",
    "\n",
    "# Show the DataFrame's head\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the real vs predicted prices as a line chart\n",
    "stocks.plot(title=\"Actual Vs. Predicted  Prices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(dataframe):\n",
    "    dataframe = lib_copy.fetch_ohlcv(ticker_symbol)\n",
    "\n",
    "    def adding_boll_kelt_ewma_dataframe(dataframe):\n",
    "        lib_copy.bollinger_band_generator(dataframe)\n",
    "        lib_copy.keltner_channel(dataframe)\n",
    "        lib_copy.ewma(dataframe)\n",
    "\n",
    "        return dataframe\n",
    "\n",
    "    everything = adding_boll_kelt_ewma_dataframe(dataframe)\n",
    "\n",
    "    everything = df.dropna()\n",
    "\n",
    "    response_data = lib_copy.signals_generator(everything)\n",
    "\n",
    "    response_data.index = response_data.index.date\n",
    "    final_df = response_data\n",
    "\n",
    "    X = final_df.iloc[:, 0:20].values\n",
    "    \n",
    "    y = final_df.iloc[:, -1].values\n",
    "\n",
    "    X, y = np.array(X), np.array(y).reshape(-1,1)\n",
    "\n",
    "    # Manually splitting the data\n",
    "    split = int(0.7 * len(X))\n",
    "\n",
    "    X_train = X[: split]\n",
    "    X_test = X[split:]\n",
    "\n",
    "    y_train = y[: split]\n",
    "    y_test = y[split:]\n",
    "\n",
    "    # Importing the MinMaxScaler from sklearn\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "    # Create a MinMaxScaler object\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the MinMaxScaler object with the features data X\n",
    "    scaler.fit(X)\n",
    "\n",
    "    # Scale the features training and testing sets\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Fit the MinMaxScaler object with the target data Y\n",
    "    scaler.fit(y)\n",
    "\n",
    "    # Scale the target training and testing sets\n",
    "    y_train = scaler.transform(y_train)\n",
    "    y_test = scaler.transform(y_test)\n",
    "\n",
    "    # Importing required Keras modules\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "    # Define the LSTM RNN model.\n",
    "    model = Sequential()\n",
    "\n",
    "    # Initial model setup\n",
    "    number_units = 30\n",
    "    dropout_fraction = 0.2\n",
    "\n",
    "    # Layer 1\n",
    "    model.add(LSTM(\n",
    "        units=number_units,\n",
    "        return_sequences=True,\n",
    "        input_shape=(X_train.shape[1], 1))\n",
    "        )\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(LSTM(units=number_units, return_sequences=True))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(LSTM(units=number_units))\n",
    "    model.add(Dropout(dropout_fraction))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, shuffle=False, batch_size=90, verbose=1)\n",
    "\n",
    "    # Make predictions using the testing data X_test\n",
    "    predicted = model.predict(X_test)\n",
    "\n",
    "    # Recover the original prices instead of the scaled version\n",
    "    predicted_prices = scaler.inverse_transform(predicted)\n",
    "    real_prices = scaler.inverse_transform(y_test.reshape(-1, 1))\n",
    "    # Create a DataFrame of Real and Predicted values\n",
    "    comparison = pd.DataFrame({\n",
    "        \"Actual\": real_prices.ravel(),\n",
    "        \"Predicted\": predicted_prices.ravel()\n",
    "    }, index = final_df.index[-len(real_prices): ]) \n",
    "\n",
    "    return model.summary(), model.evaluate(X_test, y_test, verbose=0), comparison.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python_defaultSpec_1610480620144"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}